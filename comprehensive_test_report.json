{
  "timestamp": "2025-08-26T10:40:11.916242",
  "execution_time_seconds": 182.0754051208496,
  "overall_success": false,
  "summary": {
    "total_test_types": 6,
    "successful_test_types": 0,
    "total_tests": 7,
    "tests_passed": 0,
    "tests_failed": 7,
    "tests_skipped": 0,
    "coverage_percentage": 0,
    "coverage_threshold": 95.0,
    "coverage_meets_threshold": false
  },
  "test_results": {
    "Unit Tests": {
      "success": false,
      "execution_time": 111.6316864490509,
      "return_code": 1,
      "tests_run": 0,
      "tests_passed": 0,
      "tests_failed": 0,
      "tests_skipped": 0,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.11.9, pytest-8.4.1, pluggy-1.5.0 -- C:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\ncachedir: .pytest_cache\nrootdir: D:\\ESCAI\nconfigfile: pyproject.toml\nplugins: anyio-3.7.1, langsmith-0.4.4, asyncio-1.1.0, mock-3.14.1\nasyncio: mode=Mode.AUTO, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 681 items\n\ntests/unit/test_base_instrumentor.py::TestBaseInstrumentor::test_initialization PASSED [  0%]\ntests/unit/test_base_instrumentor.py::TestBaseInstrumentor::test_initialization_with_custom_params PASSED [  0%]\ntests/unit/test_base_instrumentor.py::TestBaseInstrumentor::test_start_stop_lifecycle PASSED [  0%]\ntests/unit/test_base_instrumentor.py::TestBaseInstrumentor::test_session_management PASSED [  0%]\ntests/unit/test_base_instrumentor.py::TestBaseInstrumentor::test_event_handling PASSED [  0%]\ntests/unit/test_base_instrumentor.py::TestBaseInstrumentor::test_async_event_handler PASSED [  0%]\ntests/unit/test_base_instrumentor.py::TestBaseInstrumentor::test_event_validation PASSED [  1%]\ntests/unit/test_base_instrumentor.py::TestBaseInstrumentor::test_circuit_breaker PASSED [  1%]\ntests/unit/test_base_instrumentor.py::TestBaseInstrumentor::test_performance_metrics PASSED [  1%]\ntests/unit/test_base_instrumentor.py::TestBaseInstrumentor::test_overhead_checking PASSED [  1%]\ntests/unit/test_base_instrumentor.py::TestBaseInstrumentor::test_create_event_utility PASSED [  1%]\ntests/unit/test_base_instrumentor.py::TestBaseInstrumentor::test_multiple_sessions PASSED [  1%]\ntests/unit/test_base_instrumentor.py::TestBaseInstrumentor::test_event_queue_overflow PASSED [  1%]\ntests/unit/test_base_instrumentor.py::TestBaseInstrumentor::test_context_manager PASSED [  2%]\ntests/unit/test_base_instrumentor.py::TestBaseInstrumentor::test_stop_nonexistent_session PASSED [  2%]\ntests/unit/test_base_instrumentor.py::TestBaseInstrumentor::test_thread_safety PASSED [  2%]\ntests/unit/test_behavioral_pattern.py::TestExecutionStep::test_execution_step_creation PASSED [  2%]\ntests/unit/test_behavioral_pattern.py::TestExecutionStep::test_execution_step_validation_valid PASSED [  2%]\ntests/unit/test_behavioral_pattern.py::TestExecutionStep::test_execution_step_validation_invalid PASSED [  2%]\ntests/unit/test_behavioral_pattern.py::TestExecutionStep::test_execution_step_serialization PASSED [  2%]\ntests/unit/test_behavioral_pattern.py::TestExecutionSequence::test_execution_sequence_creation PASSED [  3%]\ntests/unit/test_behavioral_pattern.py::TestExecutionSequence::test_execution_sequence_calculate_metrics PASSED [  3%]\ntests/unit/test_behavioral_pattern.py::TestExecutionSequence::test_execution_sequence_validation PASSED [  3%]\ntests/unit/test_behavioral_pattern.py::TestExecutionSequence::test_execution_sequence_serialization PASSED [  3%]\ntests/unit/test_behavioral_pattern.py::TestBehavioralPattern::test_behavioral_pattern_creation PASSED [  3%]\ntests/unit/test_behavioral_pattern.py::TestBehavioralPattern::test_behavioral_pattern_validation PASSED [  3%]\ntests/unit/test_behavioral_pattern.py::TestBehavioralPattern::test_behavioral_pattern_calculate_statistics PASSED [  3%]\ntests/unit/test_behavioral_pattern.py::TestBehavioralPattern::test_behavioral_pattern_add_sequence PASSED [  4%]\ntests/unit/test_behavioral_pattern.py::TestBehavioralPattern::test_behavioral_pattern_serialization PASSED [  4%]\ntests/unit/test_behavioral_pattern.py::TestBehavioralPattern::test_behavioral_pattern_json_serialization PASSED [  4%]\ntests/unit/test_behavioral_pattern.py::TestBehavioralPattern::test_behavioral_pattern_with_invalid_sequences PASSED [  4%]\ntests/unit/test_causal_engine.py::TestTemporalEvent::test_temporal_event_creation PASSED [  4%]\ntests/unit/test_causal_engine.py::TestTemporalEvent::test_temporal_event_to_dict PASSED [  4%]\ntests/unit/test_causal_engine.py::TestGrangerResult::test_granger_result_creation PASSED [  4%]\ntests/unit/test_causal_engine.py::TestGrangerResult::test_granger_result_to_dict PASSED [  5%]\ntests/unit/test_causal_engine.py::TestCausalGraph::test_causal_graph_creation PASSED [  5%]\ntests/unit/test_causal_engine.py::TestCausalGraph::test_add_relationship PASSED [  5%]\ntests/unit/test_causal_engine.py::TestCausalGraph::test_get_ancestors PASSED [  5%]\ntests/unit/test_causal_engine.py::TestCausalGraph::test_get_descendants PASSED [  5%]\ntests/unit/test_causal_engine.py::TestInterventionEffect::test_intervention_effect_creation PASSED [  5%]\ntests/unit/test_causal_engine.py::TestInterventionEffect::test_intervention_effect_to_dict PASSED [  6%]\ntests/unit/test_causal_engine.py::TestCausalEngine::test_causal_engine_initialization PASSED [  6%]\ntests/unit/test_causal_engine.py::TestCausalEngine::test_causal_engine_default_initialization PASSED [  6%]\ntests/unit/test_causal_engine.py::TestCausalEngine::test_discover_relationships_insufficient_events PASSED [  6%]\ntests/unit/test_causal_engine.py::TestCausalEngine::test_discover_relationships_temporal_pattern FAILED [  6%]\ntests/unit/test_causal_engine.py::TestCausalEngine::test_test_granger_causality_missing_columns PASSED [  6%]\ntests/unit/test_causal_engine.py::TestCausalEngine::test_test_granger_causality_insufficient_data PASSED [  6%]\ntests/unit/test_causal_engine.py::TestCausalEngine::test_test_granger_causality_success PASSED [  7%]\ntests/unit/test_causal_engine.py::TestCausalEngine::test_test_granger_causality_no_statsmodels PASSED [  7%]\ntests/unit/test_causal_engine.py::TestCausalEngine::test_build_causal_graph PASSED [  7%]\ntests/unit/test_causal_engine.py::TestCausalEngine::test_analyze_interventions_missing_variables PASSED [  7%]\ntests/unit/test_causal_engine.py::TestCausalEngine::test_analyze_interventions_success PASSED [  7%]\ntests/unit/test_causal_engine.py::TestCausalEngine::test_group_events PASSED [  7%]\ntests/unit/test_causal_engine.py::TestCausalEngine::test_events_to_time_series_empty PASSED [  7%]\ntests/unit/test_causal_engine.py::TestCausalEngine::test_events_to_time_series_insufficient_time_range PASSED [  8%]\ntests/unit/test_causal_engine.py::TestCausalEngine::test_events_to_time_series_success PASSED [  8%]\ntests/unit/test_causal_engine.py::TestCausalEngine::test_granger_to_causal_relationship_non_causal PASSED [  8%]\ntests/unit/test_causal_engine.py::TestCausalEngine::test_granger_to_causal_relationship_success PASSED [  8%]\ntests/unit/test_causal_relationship.py::TestCausalEvent::test_causal_event_creation PASSED [  8%]\ntests/unit/test_causal_relationship.py::TestCausalEvent::test_causal_event_validation_valid PASSED [  8%]\ntests/unit/test_causal_relationship.py::TestCausalEvent::test_causal_event_validation_invalid PASSED [  8%]\ntests/unit/test_causal_relationship.py::TestCausalEvent::test_causal_event_serialization PASSED [  9%]\ntests/unit/test_causal_relationship.py::TestCausalEvidence::test_causal_evidence_creation PASSED [  9%]\ntests/unit/test_causal_relationship.py::TestCausalEvidence::test_causal_evidence_validation_valid PASSED [  9%]\ntests/unit/test_causal_relationship.py::TestCausalEvidence::test_causal_evidence_validation_invalid PASSED [  9%]\ntests/unit/test_causal_relationship.py::TestCausalEvidence::test_causal_evidence_serialization PASSED [  9%]\ntests/unit/test_causal_relationship.py::TestCausalRelationship::test_causal_relationship_creation PASSED [  9%]\ntests/unit/test_causal_relationship.py::TestCausalRelationship::test_causal_relationship_validation_valid PASSED [  9%]\ntests/unit/test_causal_relationship.py::TestCausalRelationship::test_causal_relationship_validation_invalid PASSED [ 10%]\ntests/unit/test_causal_relationship.py::TestCausalRelationship::test_causal_relationship_temporal_order PASSED [ 10%]\ntests/unit/test_causal_relationship.py::TestCausalRelationship::test_causal_relationship_calculate_delay PASSED [ 10%]\ntests/unit/test_causal_relationship.py::TestCausalRelationship::test_causal_relationship_add_evidence PASSED [ 10%]\ntests/unit/test_causal_relationship.py::TestCausalRelationship::test_causal_relationship_serialization PASSED [ 10%]\ntests/unit/test_causal_relationship.py::TestCausalRelationship::test_causal_relationship_json_serialization PASSED [ 10%]\ntests/unit/test_cli_console.py::TestCLIConsole::test_escai_theme_exists PASSED [ 11%]\ntests/unit/test_cli_console.py::TestCLIConsole::test_escai_theme_colors PASSED [ 11%]\ntests/unit/test_cli_console.py::TestCLIConsole::test_get_console_returns_console PASSED [ 11%]\ntests/unit/test_cli_console.py::TestCLIConsole::test_get_console_singleton PASSED [ 11%]\ntests/unit/test_cli_console.py::TestCLIConsole::test_console_has_theme PASSED [ 11%]\ntests/unit/test_cli_console.py::TestCLIConsole::test_console_theme_rendering PASSED [ 11%]\ntests/unit/test_cli_console.py::TestCLIConsole::test_console_markup_rendering PASSED [ 11%]\ntests/unit/test_cli_console.py::TestCLIConsole::test_console_properties PASSED [ 12%]\ntests/unit/test_cli_console.py::TestCLIConsole::test_theme_style_inheritance PASSED [ 12%]\ntests/unit/test_cli_console.py::TestCLIConsole::test_console_output_capture PASSED [ 12%]\ntests/unit/test_cli_console.py::TestCLIConsole::test_console_width_handling PASSED [ 12%]\ntests/unit/test_cli_console.py::TestCLIConsole::test_console_color_system PASSED [ 12%]\ntests/unit/test_cli_console.py::TestCLIConsole::test_multiple_console_instances PASSED [ 12%]\ntests/unit/test_cli_console.py::TestCLIConsole::test_console_thread_safety PASSED [ 12%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_agent_status_table_empty PASSED [ 13%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_agent_status_table_with_data PASSED [ 13%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_agent_status_table_missing_fields PASSED [ 13%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_epistemic_state_complete PASSED [ 13%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_epistemic_state_empty PASSED [ 13%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_behavioral_patterns_empty PASSED [ 13%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_behavioral_patterns_with_data PASSED [ 13%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_causal_tree_empty PASSED [ 14%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_causal_tree_with_data PASSED [ 14%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_predictions_empty PASSED [ 14%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_predictions_with_data PASSED [ 14%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_ascii_chart_empty PASSED [ 14%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_ascii_chart_single_value PASSED [ 14%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_ascii_chart_multiple_values PASSED [ 14%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_ascii_chart_custom_dimensions PASSED [ 15%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_create_progress_bar PASSED [ 15%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_epistemic_state_partial_data PASSED [ 15%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_behavioral_patterns_edge_cases PASSED [ 15%]\ntests/unit/test_cli_formatters.py::TestCLIFormatters::test_format_causal_tree_duplicate_causes PASSED [ 15%]\ntests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_extract_beliefs PASSED [ 15%]\ntests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_extract_knowledge PASSED [ 16%]\ntests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_extract_goals PASSED [ 16%]\ntests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_calculate_confidence FAILED [ 16%]\ntests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_quantify_uncertainty PASSED [ 16%]\ntests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_confidence_score_extraction FAILED [ 16%]\ntests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_belief_type_classification PASSED [ 16%]\ntests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_goal_status_classification PASSED [ 16%]\ntests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_knowledge_graph_building PASSED [ 17%]\ntests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_linguistic_confidence_analysis PASSED [ 17%]\ntests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_goal_priority_extraction PASSED [ 17%]\ntests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_empty_input_handling PASSED [ 17%]\ntests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_error_handling PASSED [ 17%]\ntests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_model_initialization_fallback PASSED [ 17%]\ntests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_shannon_entropy_calculation FAILED [ 17%]\ntests/unit/test_epistemic_state.py::TestBeliefState::test_belief_state_creation PASSED [ 18%]\ntests/unit/test_epistemic_state.py::TestBeliefState::test_belief_state_validation_valid PASSED [ 18%]\ntests/unit/test_epistemic_state.py::TestBeliefState::test_belief_state_validation_invalid_content PASSED [ 18%]\ntests/unit/test_epistemic_state.py::TestBeliefState::test_belief_state_validation_invalid_confidence PASSED [ 18%]\ntests/unit/test_epistemic_state.py::TestBeliefState::test_belief_state_serialization PASSED [ 18%]\ntests/unit/test_epistemic_state.py::TestKnowledgeState::test_knowledge_state_creation PASSED [ 18%]\ntests/unit/test_epistemic_state.py::TestKnowledgeState::test_knowledge_state_validation PASSED [ 18%]\ntests/unit/test_epistemic_state.py::TestKnowledgeState::test_knowledge_state_serialization PASSED [ 19%]\ntests/unit/test_epistemic_state.py::TestGoalState::test_goal_state_creation PASSED [ 19%]\ntests/unit/test_epistemic_state.py::TestGoalState::test_goal_state_validation PASSED [ 19%]\ntests/unit/test_epistemic_state.py::TestGoalState::test_goal_state_serialization PASSED [ 19%]\ntests/unit/test_epistemic_state.py::TestEpistemicState::test_epistemic_state_creation PASSED [ 19%]\ntests/unit/test_epistemic_state.py::TestEpistemicState::test_epistemic_state_validation PASSED [ 19%]\ntests/unit/test_epistemic_state.py::TestEpistemicState::test_epistemic_state_serialization PASSED [ 19%]\ntests/unit/test_epistemic_state.py::TestEpistemicState::test_epistemic_state_json_serialization PASSED [ 20%]\ntests/unit/test_epistemic_state.py::TestEpistemicState::test_epistemic_state_with_invalid_components PASSED [ 20%]\ntests/unit/test_epistemic_state.py::TestEpistemicState::test_epistemic_state_defaults PASSED [ 20%]\ntests/unit/test_error_handling.py::TestExceptions::test_base_exception_creation PASSED [ 20%]\ntests/unit/test_error_handling.py::TestExceptions::test_instrumentation_errors PASSED [ 20%]\ntests/unit/test_error_handling.py::TestExceptions::test_processing_errors PASSED [ 20%]\ntests/unit/test_error_handling.py::TestExceptions::test_api_errors FAILED [ 20%]\ntests/unit/test_error_handling.py::TestRetryMechanism::test_retry_config PASSED [ 21%]\ntests/unit/test_error_handling.py::TestRetryMechanism::test_exponential_backoff_with_jitter PASSED [ 21%]\ntests/unit/test_error_handling.py::TestRetryMechanism::test_async_retry_success PASSED [ 21%]\ntests/unit/test_error_handling.py::TestRetryMechanism::test_async_retry_exhausted FAILED [ 21%]\ntests/unit/test_error_handling.py::TestRetryMechanism::test_sync_retry_success PASSED [ 21%]\ntests/unit/test_error_handling.py::TestRetryMechanism::test_retry_decorator PASSED [ 21%]\ntests/unit/test_error_handling.py::TestCircuitBreaker::test_circuit_breaker_creation PASSED [ 22%]\ntests/unit/test_error_handling.py::TestCircuitBreaker::test_circuit_breaker_opens_on_failures PASSED [ 22%]\ntests/unit/test_error_handling.py::TestCircuitBreaker::test_circuit_breaker_recovery PASSED [ 22%]\ntests/unit/test_error_handling.py::TestCircuitBreaker::test_monitoring_circuit_breaker PASSED [ 22%]\ntests/unit/test_error_handling.py::TestFallbackMechanisms::test_rule_based_epistemic_extractor FAILED [ 22%]\ntests/unit/test_error_handling.py::TestFallbackMechanisms::test_fallback_manager FAILED [ 22%]\ntests/unit/test_error_handling.py::TestFallbackMechanisms::test_fallback_caching FAILED [ 22%]\ntests/unit/test_error_handling.py::TestLoadShedding::test_system_monitor PASSED [ 23%]\ntests/unit/test_error_handling.py::TestLoadShedding::test_load_level_determination PASSED [ 23%]\ntests/unit/test_error_handling.py::TestLoadShedding::test_load_shedding_behavior PASSED [ 23%]\ntests/unit/test_error_handling.py::TestLoadShedding::test_graceful_degradation_manager PASSED [ 23%]\ntests/unit/test_error_handling.py::TestErrorTracking::test_error_event_creation PASSED [ 23%]\ntests/unit/test_error_handling.py::TestErrorTracking::test_error_tracker FAILED [ 23%]\ntests/unit/test_error_handling.py::TestErrorTracking::test_error_pattern_detection PASSED [ 23%]\ntests/unit/test_error_handling.py::TestErrorTracking::test_structured_logger PASSED [ 24%]\ntests/unit/test_error_handling.py::TestErrorTracking::test_monitoring_decorator PASSED [ 24%]\ntests/unit/test_error_handling.py::TestIntegration::test_full_error_handling_pipeline FAILED [ 24%]\ntests/unit/test_error_handling.py::TestIntegration::test_circuit_breaker_with_retry FAILED [ 24%]\ntests/unit/test_event_stream.py::TestStreamFilter::test_filter_no_criteria PASSED [ 24%]\ntests/unit/test_event_stream.py::TestStreamFilter::test_filter_event_types PASSED [ 24%]\ntests/unit/test_event_stream.py::TestStreamFilter::test_filter_agent_ids PASSED [ 24%]\ntests/unit/test_event_stream.py::TestStreamFilter::test_filter_session_ids PASSED [ 25%]\ntests/unit/test_event_stream.py::TestStreamFilter::test_filter_severity_levels PASSED [ 25%]\ntests/unit/test_event_stream.py::TestStreamFilter::test_filter_frameworks PASSED [ 25%]\ntests/unit/test_event_stream.py::TestStreamFilter::test_filter_components PASSED [ 25%]\ntests/unit/test_event_stream.py::TestStreamFilter::test_filter_time_window PASSED [ 25%]\ntests/unit/test_event_stream.py::TestStreamFilter::test_filter_custom_function PASSED [ 25%]\ntests/unit/test_event_stream.py::TestStreamFilter::test_filter_multiple_criteria PASSED [ 25%]\ntests/unit/test_event_stream.py::TestEventBuffer::test_buffer_initialization PASSED [ 26%]\ntests/unit/test_event_stream.py::TestEventBuffer::test_buffer_add_events PASSED [ 26%]\ntests/unit/test_event_stream.py::TestEventBuffer::test_buffer_get_events PASSED [ 26%]\ntests/unit/test_event_stream.py::TestEventBuffer::test_buffer_clear PASSED [ 26%]\ntests/unit/test_event_stream.py::TestEventBuffer::test_buffer_thread_safety PASSED [ 26%]\ntests/unit/test_event_stream.py::TestSubscriber::test_subscriber_creation PASSED [ 26%]\ntests/unit/test_event_stream.py::TestSubscriber::test_subscriber_notify_sync_callback PASSED [ 27%]\ntests/unit/test_event_stream.py::TestSubscriber::test_subscriber_notify_async_callback PASSED [ 27%]\ntests/unit/test_event_stream.py::TestSubscriber::test_subscriber_notify_with_filter PASSED [ 27%]\ntests/unit/test_event_stream.py::TestSubscriber::test_subscriber_notify_inactive PASSED [ 27%]\ntests/unit/test_event_stream.py::TestSubscriber::test_subscriber_notify_callback_error PASSED [ 27%]\ntests/unit/test_event_stream.py::TestEventStream::test_stream_initialization PASSED [ 27%]\ntests/unit/test_event_stream.py::TestEventStream::test_stream_lifecycle PASSED [ 27%]\ntests/unit/test_event_stream.py::TestEventStream::test_stream_publish_and_subscribe PASSED [ 28%]\ntests/unit/test_event_stream.py::TestEventStream::test_stream_multiple_subscribers PASSED [ 28%]\ntests/unit/test_event_stream.py::TestEventStream::test_stream_subscribe_with_filter PASSED [ 28%]\ntests/unit/test_event_stream.py::TestEventStream::test_stream_unsubscribe PASSED [ 28%]\ntests/unit/test_event_stream.py::TestEventStream::test_stream_invalid_event PASSED [ 28%]\ntests/unit/test_event_stream.py::TestEventStream::test_stream_get_buffered_events PASSED [ 28%]\ntests/unit/test_event_stream.py::TestEventStream::test_stream_metrics PASSED [ 28%]\ntests/unit/test_event_stream.py::TestEventStream::test_stream_clear_buffer PASSED [ 29%]\ntests/unit/test_event_stream.py::TestEventStream::test_stream_duplicate_subscriber_id PASSED [ 29%]\ntests/unit/test_event_stream.py::TestFilterHelpers::test_create_agent_filter PASSED [ 29%]\ntests/unit/test_event_stream.py::TestFilterHelpers::test_create_event_type_filter PASSED [ 29%]\ntests/unit/test_event_stream.py::TestFilterHelpers::test_create_severity_filter PASSED [ 29%]\ntests/unit/test_event_stream.py::TestFilterHelpers::test_create_time_window_filter PASSED [ 29%]\ntests/unit/test_event_stream.py::TestFilterHelpers::test_create_framework_filter PASSED [ 29%]\ntests/unit/test_events.py::TestAgentEvent::test_event_creation PASSED    [ 30%]\ntests/unit/test_events.py::TestAgentEvent::test_event_validation_valid PASSED [ 30%]\ntests/unit/test_events.py::TestAgentEvent::test_event_validation_invalid_event_id PASSED [ 30%]\ntests/unit/test_events.py::TestAgentEvent::test_event_validation_invalid_confidence PASSED [ 30%]\ntests/unit/test_events.py::TestAgentEvent::test_event_to_dict PASSED     [ 30%]\ntests/unit/test_events.py::TestAgentEvent::test_event_from_dict PASSED   [ 30%]\ntests/unit/test_events.py::TestAgentEvent::test_event_json_serialization PASSED [ 30%]\ntests/unit/test_events.py::TestAgentEvent::test_event_add_tag PASSED     [ 31%]\ntests/unit/test_events.py::TestAgentEvent::test_event_set_error PASSED   [ 31%]\ntests/unit/test_events.py::TestAgentEvent::test_event_set_performance_metrics PASSED [ 31%]\ntests/unit/test_events.py::TestAgentEvent::test_event_with_all_fields PASSED [ 31%]\ntests/unit/test_events.py::TestMonitoringSession::test_session_creation PASSED [ 31%]\ntests/unit/test_events.py::TestMonitoringSession::test_session_validation_valid PASSED [ 31%]\ntests/unit/test_events.py::TestMonitoringSession::test_session_validation_invalid PASSED [ 32%]\ntests/unit/test_events.py::TestMonitoringSession::test_session_serialization PASSED [ 32%]\ntests/unit/test_events.py::TestMonitoringSummary::test_summary_creation PASSED [ 32%]\ntests/unit/test_events.py::TestMonitoringSummary::test_summary_validation_valid PASSED [ 32%]\ntests/unit/test_events.py::TestMonitoringSummary::test_summary_validation_invalid PASSED [ 32%]\ntests/unit/test_events.py::TestMonitoringSummary::test_summary_serialization PASSED [ 32%]\ntests/unit/test_events.py::TestMonitoringSummary::test_summary_event_types_count PASSED [ 32%]\ntests/unit/test_events.py::TestMonitoringSummary::test_summary_performance_metrics PASSED [ 33%]\ntests/unit/test_events.py::TestEventTypes::test_event_type_values PASSED [ 33%]\ntests/unit/test_events.py::TestEventTypes::test_event_severity_values PASSED [ 33%]\ntests/unit/test_events.py::TestEventTypes::test_enum_serialization PASSED [ 33%]\ntests/unit/test_explanation_engine.py::TestBehaviorExplanation::test_explain_behavior_simple_style PASSED [ 33%]\ntests/unit/test_explanation_engine.py::TestBehaviorExplanation::test_explain_behavior_detailed_style PASSED [ 33%]\ntests/unit/test_explanation_engine.py::TestBehaviorExplanation::test_explain_behavior_empty_data PASSED [ 33%]\ntests/unit/test_explanation_engine.py::TestDecisionPathwayExplanation::test_explain_decision_pathway_simple PASSED [ 34%]\ntests/unit/test_explanation_engine.py::TestDecisionPathwayExplanation::test_explain_decision_pathway_detailed PASSED [ 34%]\ntests/unit/test_explanation_engine.py::TestDecisionPathwayExplanation::test_explain_decision_pathway_empty_data PASSED [ 34%]\ntests/unit/test_explanation_engine.py::TestCausalExplanation::test_explain_causal_relationship_simple PASSED [ 34%]\ntests/unit/test_explanation_engine.py::TestCausalExplanation::test_explain_causal_relationship_detailed PASSED [ 34%]\ntests/unit/test_explanation_engine.py::TestCausalExplanation::test_explain_causal_relationship_empty_data PASSED [ 34%]\ntests/unit/test_explanation_engine.py::TestPredictionExplanation::test_explain_prediction_simple PASSED [ 34%]\ntests/unit/test_explanation_engine.py::TestPredictionExplanation::test_explain_prediction_detailed PASSED [ 35%]\ntests/unit/test_explanation_engine.py::TestPredictionExplanation::test_explain_prediction_empty_data PASSED [ 35%]\ntests/unit/test_explanation_engine.py::TestComparativeAnalysis::test_compare_success_failure_simple PASSED [ 35%]\ntests/unit/test_explanation_engine.py::TestComparativeAnalysis::test_compare_success_failure_detailed PASSED [ 35%]\ntests/unit/test_explanation_engine.py::TestComparativeAnalysis::test_compare_success_failure_empty_data PASSED [ 35%]\ntests/unit/test_explanation_engine.py::TestExplanationQuality::test_explanation_quality_metrics PASSED [ 35%]\ntests/unit/test_explanation_engine.py::TestExplanationQuality::test_clarity_score_calculation PASSED [ 35%]\ntests/unit/test_explanation_engine.py::TestExplanationQuality::test_actionability_score_calculation PASSED [ 36%]\ntests/unit/test_explanation_engine.py::TestHelperMethods::test_describe_strength PASSED [ 36%]\ntests/unit/test_explanation_engine.py::TestHelperMethods::test_describe_delay PASSED [ 36%]\ntests/unit/test_explanation_engine.py::TestHelperMethods::test_format_prediction_value PASSED [ 36%]\ntests/unit/test_explanation_engine.py::TestHelperMethods::test_extract_primary_goal PASSED [ 36%]\ntests/unit/test_explanation_engine.py::TestTemplateSystem::test_template_initialization PASSED [ 36%]\ntests/unit/test_explanation_engine.py::TestTemplateSystem::test_template_structure PASSED [ 37%]\ntests/unit/test_failure_analysis.py::TestFailureMode::test_creation PASSED [ 37%]\ntests/unit/test_failure_analysis.py::TestRootCause::test_creation PASSED [ 37%]\ntests/unit/test_failure_analysis.py::TestFailurePatternDetector::test_initialization PASSED [ 37%]\ntests/unit/test_failure_analysis.py::TestFailurePatternDetector::test_detect_failure_patterns ERROR [ 37%]\ntests/unit/test_failure_analysis.py::TestFailurePatternDetector::test_identify_failure_signatures ERROR [ 37%]\ntests/unit/test_failure_analysis.py::TestFailurePatternDetector::test_extract_failure_features ERROR [ 37%]\ntests/unit/test_failure_analysis.py::TestFailurePatternDetector::test_extract_cluster_signature ERROR [ 38%]\ntests/unit/test_failure_analysis.py::TestFailurePatternDetector::test_analyze_failure_characteristics ERROR [ 38%]\ntests/unit/test_failure_analysis.py::TestRootCauseAnalyzer::test_initialization PASSED [ 38%]\ntests/unit/test_failure_analysis.py::TestRootCauseAnalyzer::test_analyze_root_causes ERROR [ 38%]\ntests/unit/test_failure_analysis.py::TestRootCauseAnalyzer::test_prepare_causal_data ERROR [ 38%]\ntests/unit/test_failure_analysis.py::TestRootCauseAnalyzer::test_extract_causal_features ERROR [ 38%]\ntests/unit/test_failure_analysis.py::TestRootCauseAnalyzer::test_extract_decision_rules PASSED [ 38%]\ntests/unit/test_failure_analysis.py::TestRootCauseAnalyzer::test_interpret_rule_conditions PASSED [ 39%]\ntests/unit/test_failure_analysis.py::TestRootCauseAnalyzer::test_extract_contributing_factors PASSED [ 39%]\ntests/unit/test_failure_analysis.py::TestRootCauseAnalyzer::test_trace_causal_chain PASSED [ 39%]\ntests/unit/test_failure_analysis.py::TestFailureAnalysisEngine::test_initialization PASSED [ 39%]\ntests/unit/test_failure_analysis.py::TestFailureAnalysisEngine::test_analyze_failures ERROR [ 39%]\ntests/unit/test_failure_analysis.py::TestFailureAnalysisEngine::test_calculate_failure_severity ERROR [ 39%]\ntests/unit/test_failure_analysis.py::TestFailureAnalysisEngine::test_extract_common_triggers ERROR [ 39%]\ntests/unit/test_failure_analysis.py::TestFailureAnalysisEngine::test_generate_failure_name PASSED [ 40%]\ntests/unit/test_failure_analysis.py::TestFailureAnalysisEngine::test_generate_failure_description PASSED [ 40%]\ntests/unit/test_failure_analysis.py::TestFailureAnalysisEngine::test_suggest_recovery_strategies PASSED [ 40%]\ntests/unit/test_failure_analysis.py::TestFailureAnalysisEngine::test_suggest_prevention_measures PASSED [ 40%]\ntests/unit/test_failure_analysis.py::TestFailureAnalysisEngine::test_identify_risk_factors PASSED [ 40%]\ntests/unit/test_failure_analysis.py::TestFailureAnalysisEngine::test_generate_recommendations PASSED [ 40%]\ntests/unit/test_failure_analysis.py::TestFailureAnalysisIntegration::test_end_to_end_failure_analysis ERROR [ 40%]\ntests/unit/test_failure_analysis.py::TestFailureAnalysisIntegration::test_pattern_detection_with_real_clustering ERROR [ 41%]\ntests/unit/test_failure_analysis.py::TestFailureAnalysisIntegration::test_failure_signature_analysis ERROR [ 41%]\ntests/unit/test_failure_analysis.py::TestFailureAnalysisIntegration::test_root_cause_analysis_with_real_data ERROR [ 41%]\ntests/unit/test_influx_manager.py::TestInfluxDBManager::test_init PASSED [ 41%]\ntests/unit/test_influx_manager.py::TestInfluxDBManager::test_init_without_influxdb PASSED [ 41%]\ntests/unit/test_influx_manager.py::TestInfluxDBManager::test_metric_schemas PASSED [ 41%]\ntests/unit/test_influx_manager.py::TestInfluxDBManager::test_validate_metric_point_valid PASSED [ 41%]\ntests/unit/test_influx_manager.py::TestInfluxDBManager::test_validate_metric_point_missing_tags PASSED [ 42%]\ntests/unit/test_influx_manager.py::TestInfluxDBManager::test_validate_metric_point_missing_fields PASSED [ 42%]\ntests/unit/test_influx_manager.py::TestInfluxDBManager::test_validate_metric_point_unknown_measurement PASSED [ 42%]\ntests/unit/test_influx_manager.py::TestInfluxDBManager::test_create_influx_point PASSED [ 42%]\ntests/unit/test_influx_manager.py::TestInfluxDBManager::test_write_metric_not_connected PASSED [ 42%]\ntests/unit/test_influx_manager.py::TestInfluxDBManager::test_write_metric_invalid_point PASSED [ 42%]\ntests/unit/test_influx_manager.py::TestInfluxDBManager::test_write_metrics_batch_empty PASSED [ 43%]\ntests/unit/test_influx_manager.py::TestInfluxDBManager::test_write_metrics_batch_with_invalid_metrics PASSED [ 43%]\ntests/unit/test_influx_manager.py::TestInfluxDBManager::test_query_metrics_not_connected PASSED [ 43%]\ntests/unit/test_influx_manager.py::TestInfluxDBManager::test_query_metrics_with_bucket_injection PASSED [ 43%]\ntests/unit/test_influx_manager.py::TestInfluxDBManager::test_health_check_not_connected PASSED [ 43%]\ntests/unit/test_influx_manager.py::TestInfluxDBManager::test_health_check_with_exception PASSED [ 43%]\ntests/unit/test_influx_manager.py::TestInfluxDBManager::test_retention_policy PASSED [ 43%]\ntests/unit/test_influx_manager.py::TestConvenienceFunctions::test_write_agent_performance_metric PASSED [ 44%]\ntests/unit/test_influx_manager.py::TestConvenienceFunctions::test_write_api_metric PASSED [ 44%]\ntests/unit/test_influx_manager.py::TestConvenienceFunctions::test_write_system_metric PASSED [ 44%]\ntests/unit/test_influx_manager.py::TestMetricPoint::test_metric_point_creation PASSED [ 44%]\ntests/unit/test_influx_manager.py::TestMetricPoint::test_metric_point_default_timestamp PASSED [ 44%]\ntests/unit/test_influx_models.py::TestMetricType::test_metric_type_values PASSED [ 44%]\ntests/unit/test_influx_models.py::TestBaseMetric::test_base_metric_abstract_methods PASSED [ 44%]\ntests/unit/test_influx_models.py::TestBaseMetric::test_base_metric_to_influx_point PASSED [ 45%]\ntests/unit/test_influx_models.py::TestAgentPerformanceMetric::test_agent_performance_metric_creation PASSED [ 45%]\ntests/unit/test_influx_models.py::TestAgentPerformanceMetric::test_agent_performance_metric_tags PASSED [ 45%]\ntests/unit/test_influx_models.py::TestAgentPerformanceMetric::test_agent_performance_metric_measurement_name PASSED [ 45%]\ntests/unit/test_influx_models.py::TestAgentPerformanceMetric::test_agent_performance_metric_fields PASSED [ 45%]\ntests/unit/test_influx_models.py::TestAgentPerformanceMetric::test_agent_performance_metric_to_influx_point PASSED [ 45%]\ntests/unit/test_influx_models.py::TestAPIMetric::test_api_metric_creation PASSED [ 45%]\ntests/unit/test_influx_models.py::TestAPIMetric::test_api_metric_tags_with_user_id PASSED [ 46%]\ntests/unit/test_influx_models.py::TestAPIMetric::test_api_metric_tags_without_user_id PASSED [ 46%]\ntests/unit/test_influx_models.py::TestAPIMetric::test_api_metric_measurement_name PASSED [ 46%]\ntests/unit/test_influx_models.py::TestAPIMetric::test_api_metric_fields PASSED [ 46%]\ntests/unit/test_influx_models.py::TestSystemMetric::test_system_metric_creation PASSED [ 46%]\ntests/unit/test_influx_models.py::TestSystemMetric::test_system_metric_tags PASSED [ 46%]\ntests/unit/test_influx_models.py::TestSystemMetric::test_system_metric_measurement_name PASSED [ 46%]\ntests/unit/test_influx_models.py::TestSystemMetric::test_system_metric_fields PASSED [ 47%]\ntests/unit/test_influx_models.py::TestPredictionMetric::test_prediction_metric_creation PASSED [ 47%]\ntests/unit/test_influx_models.py::TestPredictionMetric::test_prediction_metric_fields_with_optional_values PASSED [ 47%]\ntests/unit/test_influx_models.py::TestPredictionMetric::test_prediction_metric_fields_without_optional_values PASSED [ 47%]\ntests/unit/test_influx_models.py::TestPatternMetric::test_pattern_metric_creation PASSED [ 47%]\ntests/unit/test_influx_models.py::TestPatternMetric::test_pattern_metric_tags_with_pattern_id PASSED [ 47%]\ntests/unit/test_influx_models.py::TestPatternMetric::test_pattern_metric_tags_without_pattern_id PASSED [ 48%]\ntests/unit/test_influx_models.py::TestCausalMetric::test_causal_metric_creation PASSED [ 48%]\ntests/unit/test_influx_models.py::TestCausalMetric::test_causal_metric_measurement_name PASSED [ 48%]\ntests/unit/test_influx_models.py::TestEpistemicMetric::test_epistemic_metric_creation PASSED [ 48%]\ntests/unit/test_influx_models.py::TestEpistemicMetric::test_epistemic_metric_measurement_name PASSED [ 48%]\ntests/unit/test_influx_models.py::TestMetricBatch::test_metric_batch_creation PASSED [ 48%]\ntests/unit/test_influx_models.py::TestMetricBatch::test_metric_batch_add_metric PASSED [ 48%]\ntests/unit/test_influx_models.py::TestMetricBatch::test_metric_batch_add_metrics PASSED [ 49%]\ntests/unit/test_influx_models.py::TestMetricBatch::test_metric_batch_clear PASSED [ 49%]\ntests/unit/test_influx_models.py::TestMetricBatch::test_metric_batch_to_influx_points PASSED [ 49%]\ntests/unit/test_influx_models.py::TestMetricBatch::test_metric_batch_filter_by_type PASSED [ 49%]\ntests/unit/test_influx_models.py::TestUtilityFunctions::test_create_agent_performance_metric PASSED [ 49%]\ntests/unit/test_influx_models.py::TestUtilityFunctions::test_create_api_metric PASSED [ 49%]\ntests/unit/test_influx_models.py::TestUtilityFunctions::test_create_system_metric PASSED [ 49%]\ntests/unit/test_influx_models.py::TestUtilityFunctions::test_create_prediction_metric PASSED [ 50%]\ntests/unit/test_influx_models.py::TestUtilityFunctions::test_create_pattern_metric PASSED [ 50%]\ntests/unit/test_influx_models.py::TestUtilityFunctions::test_create_causal_metric PASSED [ 50%]\ntests/unit/test_influx_models.py::TestUtilityFunctions::test_create_epistemic_metric PASSED [ 50%]\ntests/unit/test_influx_models.py::TestUtilityFunctions::test_create_metric_with_default_timestamp PASSED [ 50%]\ntests/unit/test_log_processor.py::TestLogEntry::test_log_entry_creation PASSED [ 50%]\ntests/unit/test_log_processor.py::TestLogEntry::test_log_entry_validation_valid PASSED [ 50%]\ntests/unit/test_log_processor.py::TestLogEntry::test_log_entry_validation_invalid PASSED [ 51%]\ntests/unit/test_log_processor.py::TestProcessingRule::test_rule_creation PASSED [ 51%]\ntests/unit/test_log_processor.py::TestProcessingRule::test_rule_matches_positive PASSED [ 51%]\ntests/unit/test_log_processor.py::TestProcessingRule::test_rule_matches_negative PASSED [ 51%]\ntests/unit/test_log_processor.py::TestProcessingRule::test_rule_extract_fields PASSED [ 51%]\ntests/unit/test_log_processor.py::TestProcessingRule::test_rule_with_condition PASSED [ 51%]\ntests/unit/test_log_processor.py::TestLogProcessor::test_processor_initialization PASSED [ 51%]\ntests/unit/test_log_processor.py::TestLogProcessor::test_add_remove_rules PASSED [ 52%]\ntests/unit/test_log_processor.py::TestLogProcessor::test_process_log_entry_success PASSED [ 52%]\ntests/unit/test_log_processor.py::TestLogProcessor::test_process_log_entry_no_match PASSED [ 52%]\ntests/unit/test_log_processor.py::TestLogProcessor::test_process_log_entry_invalid PASSED [ 52%]\ntests/unit/test_log_processor.py::TestLogProcessor::test_process_log_batch PASSED [ 52%]\ntests/unit/test_log_processor.py::TestLogProcessor::test_process_empty_batch PASSED [ 52%]\ntests/unit/test_log_processor.py::TestLogProcessor::test_parse_json_log_line PASSED [ 53%]\ntests/unit/test_log_processor.py::TestLogProcessor::test_parse_text_log_line PASSED [ 53%]\ntests/unit/test_log_processor.py::TestLogProcessor::test_parse_invalid_log_line PASSED [ 53%]\ntests/unit/test_log_processor.py::TestLogProcessor::test_metrics_tracking PASSED [ 53%]\ntests/unit/test_log_processor.py::TestLogProcessor::test_severity_mapping PASSED [ 53%]\ntests/unit/test_log_processor.py::TestLogProcessor::test_field_extraction PASSED [ 53%]\ntests/unit/test_log_processor.py::TestLogProcessor::test_processor_shutdown PASSED [ 53%]\ntests/unit/test_model_evaluation.py::TestModelPerformance::test_creation PASSED [ 54%]\ntests/unit/test_model_evaluation.py::TestEvaluationResult::test_creation PASSED [ 54%]\ntests/unit/test_model_evaluation.py::TestModelEvaluator::test_initialization PASSED [ 54%]\ntests/unit/test_model_evaluation.py::TestModelEvaluator::test_evaluate_ensemble_model ERROR [ 54%]\ntests/unit/test_model_evaluation.py::TestModelEvaluator::test_evaluate_online_model ERROR [ 54%]\ntests/unit/test_model_evaluation.py::TestModelEvaluator::test_cross_validate_model FAILED [ 54%]\ntests/unit/test_model_evaluation.py::TestModelEvaluator::test_compare_models PASSED [ 54%]\ntests/unit/test_model_evaluation.py::TestModelEvaluator::test_hyperparameter_tuning FAILED [ 55%]\ntests/unit/test_model_evaluation.py::TestModelEvaluator::test_determine_best_model PASSED [ 55%]\ntests/unit/test_model_evaluation.py::TestModelEvaluator::test_generate_comparison_metrics PASSED [ 55%]\ntests/unit/test_model_evaluation.py::TestModelEvaluator::test_generate_recommendations PASSED [ 55%]\ntests/unit/test_model_evaluation.py::TestModelEvaluator::test_save_and_load_evaluation_results PASSED [ 55%]\ntests/unit/test_model_evaluation.py::TestModelEvaluationIntegration::test_complete_evaluation_workflow ERROR [ 55%]\ntests/unit/test_model_evaluation.py::TestModelEvaluationIntegration::test_model_comparison_workflow FAILED [ 55%]\ntests/unit/test_model_evaluation.py::TestModelEvaluationIntegration::test_hyperparameter_optimization_workflow FAILED [ 56%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerInitialization::test_manager_initialization PASSED [ 56%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerInitialization::test_manager_default_parameters PASSED [ 56%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerConnection::test_successful_connection FAILED [ 56%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerConnection::test_connection_failure PASSED [ 56%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerConnection::test_disconnect PASSED [ 56%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerNodeOperations::test_create_node_success FAILED [ 56%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerNodeOperations::test_create_node_failure FAILED [ 57%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerNodeOperations::test_create_node_no_result FAILED [ 57%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerRelationshipOperations::test_create_relationship_success FAILED [ 57%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerRelationshipOperations::test_create_relationship_failure FAILED [ 57%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerQueryOperations::test_find_causal_paths_success FAILED [ 57%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerQueryOperations::test_find_causal_paths_empty_result FAILED [ 57%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerQueryOperations::test_get_node_centrality_success FAILED [ 58%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerQueryOperations::test_execute_custom_query_success FAILED [ 58%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerQueryOperations::test_delete_node_success FAILED [ 58%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerQueryOperations::test_get_graph_statistics_success FAILED [ 58%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerAnalysisOperations::test_analyze_causal_patterns_success FAILED [ 58%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerAnalysisOperations::test_analyze_causal_patterns_failure FAILED [ 58%]\ntests/unit/test_neo4j_manager.py::TestCreateCausalRelationshipGraph::test_create_causal_relationship_graph_success PASSED [ 58%]\ntests/unit/test_neo4j_manager.py::TestCreateCausalRelationshipGraph::test_create_causal_relationship_graph_node_failure PASSED [ 59%]\ntests/unit/test_neo4j_manager.py::TestCreateCausalRelationshipGraph::test_create_causal_relationship_graph_relationship_failure PASSED [ 59%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerErrorHandling::test_query_execution_exception_handling FAILED [ 59%]\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerErrorHandling::test_session_context_manager_exception PASSED [ 59%]\ntests/unit/test_neo4j_models.py::TestNodeType::test_node_type_values PASSED [ 59%]\ntests/unit/test_neo4j_models.py::TestRelationshipType::test_relationship_type_values PASSED [ 59%]\ntests/unit/test_neo4j_models.py::TestGraphNode::test_graph_node_creation PASSED [ 59%]\ntests/unit/test_neo4j_models.py::TestGraphNode::test_cypher_properties_conversion PASSED [ 60%]\ntests/unit/test_neo4j_models.py::TestGraphNode::test_cypher_properties_with_none_values PASSED [ 60%]\ntests/unit/test_neo4j_models.py::TestGraphRelationship::test_graph_relationship_creation PASSED [ 60%]\ntests/unit/test_neo4j_models.py::TestGraphRelationship::test_relationship_cypher_properties PASSED [ 60%]\ntests/unit/test_neo4j_models.py::TestCausalNode::test_causal_node_creation PASSED [ 60%]\ntests/unit/test_neo4j_models.py::TestCausalNode::test_causal_node_with_additional_properties PASSED [ 60%]\ntests/unit/test_neo4j_models.py::TestCausalRelationship::test_causal_relationship_creation PASSED [ 60%]\ntests/unit/test_neo4j_models.py::TestCausalRelationship::test_causal_relationship_with_optional_properties PASSED [ 61%]\ntests/unit/test_neo4j_models.py::TestKnowledgeNode::test_knowledge_node_creation PASSED [ 61%]\ntests/unit/test_neo4j_models.py::TestKnowledgeNode::test_knowledge_node_with_additional_properties PASSED [ 61%]\ntests/unit/test_neo4j_models.py::TestAgentNode::test_agent_node_creation PASSED [ 61%]\ntests/unit/test_neo4j_models.py::TestAgentNode::test_agent_node_with_additional_properties PASSED [ 61%]\ntests/unit/test_neo4j_models.py::TestGraphQuery::test_graph_query_creation PASSED [ 61%]\ntests/unit/test_neo4j_models.py::TestGraphQuery::test_graph_query_string_representation PASSED [ 61%]\ntests/unit/test_neo4j_models.py::TestGraphAnalysisResult::test_graph_analysis_result_creation PASSED [ 62%]\ntests/unit/test_neo4j_models.py::TestGraphAnalysisResult::test_graph_analysis_result_to_dict PASSED [ 62%]\ntests/unit/test_neo4j_models.py::TestDataValidation::test_empty_properties PASSED [ 62%]\ntests/unit/test_neo4j_models.py::TestDataValidation::test_special_characters_in_properties PASSED [ 62%]\ntests/unit/test_neo4j_models.py::TestDataValidation::test_large_property_values PASSED [ 62%]\ntests/unit/test_neo4j_models.py::TestDataValidation::test_datetime_serialization PASSED [ 62%]\ntests/unit/test_neo4j_models.py::TestDataValidation::test_invalid_node_type PASSED [ 62%]\ntests/unit/test_neo4j_models.py::TestDataValidation::test_negative_strength_and_confidence PASSED [ 63%]\ntests/unit/test_neo4j_models.py::TestDataValidation::test_very_large_numbers PASSED [ 63%]\ntests/unit/test_pattern_mining.py::TestPrefixSpanMiner::test_initialization PASSED [ 63%]\ntests/unit/test_pattern_mining.py::TestPrefixSpanMiner::test_mine_patterns ERROR [ 63%]\ntests/unit/test_pattern_mining.py::TestPrefixSpanMiner::test_convert_to_item_sequences ERROR [ 63%]\ntests/unit/test_pattern_mining.py::TestPrefixSpanMiner::test_find_frequent_items PASSED [ 63%]\ntests/unit/test_pattern_mining.py::TestPrefixSpanMiner::test_find_suffix PASSED [ 64%]\ntests/unit/test_pattern_mining.py::TestSPADEMiner::test_initialization PASSED [ 64%]\ntests/unit/test_pattern_mining.py::TestSPADEMiner::test_mine_patterns ERROR [ 64%]\ntests/unit/test_pattern_mining.py::TestSPADEMiner::test_build_vertical_database ERROR [ 64%]\ntests/unit/test_pattern_mining.py::TestSPADEMiner::test_find_frequent_1_sequences ERROR [ 64%]\ntests/unit/test_pattern_mining.py::TestSPADEMiner::test_can_join PASSED  [ 64%]\ntests/unit/test_pattern_mining.py::TestSPADEMiner::test_join_patterns PASSED [ 64%]\ntests/unit/test_pattern_mining.py::TestPatternClusterer::test_initialization PASSED [ 65%]\ntests/unit/test_pattern_mining.py::TestPatternClusterer::test_cluster_patterns PASSED [ 65%]\ntests/unit/test_pattern_mining.py::TestPatternClusterer::test_cluster_empty_patterns PASSED [ 65%]\ntests/unit/test_pattern_mining.py::TestPatternClusterer::test_extract_features PASSED [ 65%]\ntests/unit/test_pattern_mining.py::TestPatternMiningEngine::test_initialization PASSED [ 65%]\ntests/unit/test_pattern_mining.py::TestPatternMiningEngine::test_mine_behavioral_patterns ERROR [ 65%]\ntests/unit/test_pattern_mining.py::TestPatternMiningEngine::test_combine_patterns PASSED [ 65%]\ntests/unit/test_pattern_mining.py::TestPatternMiningEngine::test_extract_common_triggers PASSED [ 66%]\ntests/unit/test_pattern_mining.py::TestSequentialPattern::test_creation PASSED [ 66%]\ntests/unit/test_pattern_mining.py::TestPatternMiningConfig::test_default_config PASSED [ 66%]\ntests/unit/test_pattern_mining.py::TestPatternMiningConfig::test_custom_config PASSED [ 66%]\ntests/unit/test_pattern_mining.py::TestPatternMiningIntegration::test_end_to_end_pattern_mining ERROR [ 66%]\ntests/unit/test_pattern_mining.py::TestPatternMiningIntegration::test_pattern_mining_performance ERROR [ 66%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_predict_success_basic PASSED [ 66%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_predict_success_with_high_confidence PASSED [ 67%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_predict_success_with_low_confidence PASSED [ 67%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_estimate_completion_time_basic PASSED [ 67%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_estimate_completion_time_empty_history PASSED [ 67%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_identify_risk_factors_basic PASSED [ 67%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_identify_risk_factors_low_confidence PASSED [ 67%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_recommend_interventions_high_risk PASSED [ 67%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_recommend_interventions_medium_risk PASSED [ 68%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_extract_features_from_state PASSED [ 68%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_predict_with_ensemble_basic PASSED [ 68%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_predict_with_ensemble_empty_features PASSED [ 68%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_heuristic_prediction_success PASSED [ 68%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_heuristic_prediction_completion_time PASSED [ 68%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_extract_temporal_sequence PASSED [ 69%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_calculate_confidence_interval PASSED [ 69%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_calculate_prediction_confidence PASSED [ 69%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_comprehensive_feature_extraction PASSED [ 69%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_calculate_risk_score PASSED [ 69%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_calculate_risk_probability PASSED [ 69%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_error_handling_predict_success PASSED [ 69%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_error_handling_estimate_completion_time PASSED [ 70%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_model_initialization PASSED [ 70%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_risk_factor_definitions PASSED [ 70%]\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_intervention_templates PASSED [ 70%]\ntests/unit/test_performance_predictor.py::TestLSTMPredictor::test_lstm_initialization PASSED [ 70%]\ntests/unit/test_performance_predictor.py::TestLSTMPredictor::test_lstm_forward_pass PASSED [ 70%]\ntests/unit/test_performance_predictor.py::TestExecutionStep::test_execution_step_creation PASSED [ 70%]\ntests/unit/test_performance_predictor.py::TestExecutionStep::test_execution_step_to_dict PASSED [ 71%]\ntests/unit/test_performance_predictor.py::TestAgentState::test_agent_state_creation PASSED [ 71%]\ntests/unit/test_performance_predictor.py::TestAgentState::test_agent_state_to_dict PASSED [ 71%]\ntests/unit/test_performance_predictor.py::TestTimeEstimate::test_time_estimate_creation PASSED [ 71%]\ntests/unit/test_performance_predictor.py::TestTimeEstimate::test_time_estimate_to_dict PASSED [ 71%]\ntests/unit/test_postgresql_models.py::TestDatabaseManager::test_database_manager_initialization PASSED [ 71%]\ntests/unit/test_postgresql_models.py::TestDatabaseManager::test_database_manager_properties PASSED [ 71%]\ntests/unit/test_postgresql_models.py::TestSQLAlchemyModels::test_agent_model_creation PASSED [ 72%]\ntests/unit/test_postgresql_models.py::TestSQLAlchemyModels::test_monitoring_session_model_creation PASSED [ 72%]\ntests/unit/test_postgresql_models.py::TestSQLAlchemyModels::test_epistemic_state_model_creation PASSED [ 72%]\ntests/unit/test_postgresql_models.py::TestSQLAlchemyModels::test_behavioral_pattern_model_creation PASSED [ 72%]\ntests/unit/test_postgresql_models.py::TestSQLAlchemyModels::test_causal_relationship_model_creation PASSED [ 72%]\ntests/unit/test_postgresql_models.py::TestSQLAlchemyModels::test_prediction_model_creation PASSED [ 72%]\ntests/unit/test_postgresql_models.py::TestRepositoryImports::test_repository_imports PASSED [ 72%]\ntests/unit/test_postgresql_models.py::TestModelValidation::test_agent_required_fields PASSED [ 73%]\ntests/unit/test_postgresql_models.py::TestModelValidation::test_epistemic_state_timestamp_required PASSED [ 73%]\ntests/unit/test_postgresql_models.py::TestModelValidation::test_causal_relationship_required_fields PASSED [ 73%]\ntests/unit/test_prediction_models.py::TestLSTMPredictor::test_initialization PASSED [ 73%]\ntests/unit/test_prediction_models.py::TestLSTMPredictor::test_forward_pass FAILED [ 73%]\ntests/unit/test_prediction_models.py::TestSequenceDataset::test_initialization PASSED [ 73%]\ntests/unit/test_prediction_models.py::TestSequenceDataset::test_getitem PASSED [ 74%]\ntests/unit/test_prediction_models.py::TestEnsemblePredictor::test_initialization PASSED [ 74%]\ntests/unit/test_prediction_models.py::TestEnsemblePredictor::test_train ERROR [ 74%]\ntests/unit/test_prediction_models.py::TestEnsemblePredictor::test_prepare_features ERROR [ 74%]\ntests/unit/test_prediction_models.py::TestEnsemblePredictor::test_extract_sequence_features ERROR [ 74%]\ntests/unit/test_prediction_models.py::TestEnsemblePredictor::test_extract_static_features ERROR [ 74%]\ntests/unit/test_prediction_models.py::TestEnsemblePredictor::test_calculate_confidence PASSED [ 74%]\ntests/unit/test_prediction_models.py::TestEnsemblePredictor::test_identify_risk_factors ERROR [ 75%]\ntests/unit/test_prediction_models.py::TestOnlineLearningPredictor::test_initialization FAILED [ 75%]\ntests/unit/test_prediction_models.py::TestOnlineLearningPredictor::test_learn_online FAILED [ 75%]\ntests/unit/test_prediction_models.py::TestOnlineLearningPredictor::test_predict_online FAILED [ 75%]\ntests/unit/test_prediction_models.py::TestOnlineLearningPredictor::test_detect_concept_drift FAILED [ 75%]\ntests/unit/test_prediction_models.py::TestOnlineLearningPredictor::test_adapt_to_drift FAILED [ 75%]\ntests/unit/test_prediction_models.py::TestHyperparameterTuner::test_initialization PASSED [ 75%]\ntests/unit/test_prediction_models.py::TestHyperparameterTuner::test_tune_random_forest FAILED [ 76%]\ntests/unit/test_prediction_models.py::TestHyperparameterTuner::test_tune_xgboost FAILED [ 76%]\ntests/unit/test_prediction_models.py::TestModelConfig::test_default_config PASSED [ 76%]\ntests/unit/test_prediction_models.py::TestModelConfig::test_custom_config PASSED [ 76%]\ntests/unit/test_prediction_models.py::TestPredictionModelsIntegration::test_ensemble_prediction_workflow ERROR [ 76%]\ntests/unit/test_prediction_models.py::TestPredictionModelsIntegration::test_online_learning_workflow ERROR [ 76%]\ntests/unit/test_prediction_models.py::TestPredictionModelsIntegration::test_model_performance_comparison PASSED [ 76%]\ntests/unit/test_prediction_result.py::TestRiskFactor::test_risk_factor_creation PASSED [ 77%]\ntests/unit/test_prediction_result.py::TestRiskFactor::test_risk_factor_validation_valid PASSED [ 77%]\ntests/unit/test_prediction_result.py::TestRiskFactor::test_risk_factor_validation_invalid PASSED [ 77%]\ntests/unit/test_prediction_result.py::TestRiskFactor::test_risk_factor_calculate_risk_score PASSED [ 77%]\ntests/unit/test_prediction_result.py::TestRiskFactor::test_risk_factor_serialization PASSED [ 77%]\ntests/unit/test_prediction_result.py::TestIntervention::test_intervention_creation PASSED [ 77%]\ntests/unit/test_prediction_result.py::TestIntervention::test_intervention_validation_valid PASSED [ 77%]\ntests/unit/test_prediction_result.py::TestIntervention::test_intervention_validation_invalid PASSED [ 78%]\ntests/unit/test_prediction_result.py::TestIntervention::test_intervention_benefit_cost_ratio PASSED [ 78%]\ntests/unit/test_prediction_result.py::TestIntervention::test_intervention_serialization PASSED [ 78%]\ntests/unit/test_prediction_result.py::TestConfidenceInterval::test_confidence_interval_creation PASSED [ 78%]\ntests/unit/test_prediction_result.py::TestConfidenceInterval::test_confidence_interval_validation_valid PASSED [ 78%]\ntests/unit/test_prediction_result.py::TestConfidenceInterval::test_confidence_interval_validation_invalid PASSED [ 78%]\ntests/unit/test_prediction_result.py::TestConfidenceInterval::test_confidence_interval_width PASSED [ 79%]\ntests/unit/test_prediction_result.py::TestConfidenceInterval::test_confidence_interval_contains PASSED [ 79%]\ntests/unit/test_prediction_result.py::TestConfidenceInterval::test_confidence_interval_serialization PASSED [ 79%]\ntests/unit/test_prediction_result.py::TestPredictionResult::test_prediction_result_creation PASSED [ 79%]\ntests/unit/test_prediction_result.py::TestPredictionResult::test_prediction_result_validation_valid PASSED [ 79%]\ntests/unit/test_prediction_result.py::TestPredictionResult::test_prediction_result_validation_invalid PASSED [ 79%]\ntests/unit/test_prediction_result.py::TestPredictionResult::test_prediction_result_expiration PASSED [ 79%]\ntests/unit/test_prediction_result.py::TestPredictionResult::test_prediction_result_calculate_overall_risk_score PASSED [ 80%]\ntests/unit/test_prediction_result.py::TestPredictionResult::test_prediction_result_add_risk_factor PASSED [ 80%]\ntests/unit/test_prediction_result.py::TestPredictionResult::test_prediction_result_validate_prediction PASSED [ 80%]\ntests/unit/test_prediction_result.py::TestPredictionResult::test_prediction_result_serialization PASSED [ 80%]\ntests/unit/test_prediction_result.py::TestPredictionResult::test_prediction_result_json_serialization PASSED [ 80%]\ntests/unit/test_redis_manager.py::TestRedisManagerInitialization::test_redis_manager_init PASSED [ 80%]\ntests/unit/test_redis_manager.py::TestRedisManagerInitialization::test_redis_manager_initialize_success PASSED [ 80%]\ntests/unit/test_redis_manager.py::TestRedisManagerInitialization::test_redis_manager_initialize_failure_with_failover PASSED [ 81%]\ntests/unit/test_redis_manager.py::TestRedisManagerInitialization::test_redis_manager_initialize_failure_without_failover PASSED [ 81%]\ntests/unit/test_redis_manager.py::TestRedisManagerInitialization::test_redis_manager_double_initialization PASSED [ 81%]\ntests/unit/test_redis_manager.py::TestRedisManagerConnectionTesting::test_test_connection_success PASSED [ 81%]\ntests/unit/test_redis_manager.py::TestRedisManagerConnectionTesting::test_test_connection_failure PASSED [ 81%]\ntests/unit/test_redis_manager.py::TestRedisManagerConnectionTesting::test_test_connection_no_client PASSED [ 81%]\ntests/unit/test_redis_manager.py::TestRedisManagerConnectionTesting::test_available_property PASSED [ 81%]\ntests/unit/test_redis_manager.py::TestRedisManagerRetryLogic::test_execute_with_retry_success PASSED [ 82%]\ntests/unit/test_redis_manager.py::TestRedisManagerRetryLogic::test_execute_with_retry_failure_with_failover PASSED [ 82%]\ntests/unit/test_redis_manager.py::TestRedisManagerRetryLogic::test_execute_with_retry_failure_without_failover PASSED [ 82%]\ntests/unit/test_redis_manager.py::TestRedisManagerRetryLogic::test_execute_with_retry_no_client_with_failover PASSED [ 82%]\ntests/unit/test_redis_manager.py::TestRedisManagerRetryLogic::test_execute_with_retry_no_client_without_failover PASSED [ 82%]\ntests/unit/test_redis_manager.py::TestRedisManagerRetryLogic::test_execute_with_retry_exponential_backoff PASSED [ 82%]\ntests/unit/test_redis_manager.py::TestRedisManagerDataSerialization::test_session_data_serialization PASSED [ 82%]\ntests/unit/test_redis_manager.py::TestRedisManagerDataSerialization::test_cache_complex_data_serialization PASSED [ 83%]\ntests/unit/test_redis_manager.py::TestRedisManagerCleanup::test_close_connections PASSED [ 83%]\ntests/unit/test_redis_manager.py::TestRedisManagerCleanup::test_close_no_connections PASSED [ 83%]\ntests/unit/test_redis_manager.py::TestRedisManagerEnvironmentConfiguration::test_environment_variable_configuration PASSED [ 83%]\ntests/unit/test_redis_manager.py::TestRedisManagerEnvironmentConfiguration::test_default_configuration PASSED [ 83%]\ntests/unit/test_redis_manager.py::TestRedisManagerEdgeCases::test_rate_limit_with_redis_unavailable PASSED [ 83%]\ntests/unit/test_redis_manager.py::TestRedisManagerEdgeCases::test_stream_operations_with_redis_unavailable PASSED [ 83%]\ntests/unit/test_redis_manager.py::TestRedisManagerEdgeCases::test_pubsub_with_redis_unavailable PASSED [ 84%]\ntests/unit/test_redis_manager.py::TestRedisManagerEdgeCases::test_health_monitoring_with_redis_unavailable PASSED [ 84%]\ntests/unit/test_serialization.py::TestESCAIJSONEncoder::test_encode_datetime PASSED [ 84%]\ntests/unit/test_serialization.py::TestESCAIJSONEncoder::test_encode_enum PASSED [ 84%]\ntests/unit/test_serialization.py::TestESCAIJSONEncoder::test_encode_model_with_to_dict PASSED [ 84%]\ntests/unit/test_serialization.py::TestESCAIJSONEncoder::test_encode_set PASSED [ 84%]\ntests/unit/test_serialization.py::TestESCAIJSONEncoder::test_encode_tuple PASSED [ 85%]\ntests/unit/test_serialization.py::TestESCAIJSONEncoder::test_encode_bytes PASSED [ 85%]\ntests/unit/test_serialization.py::TestESCAIJSONDecoder::test_decode_datetime PASSED [ 85%]\ntests/unit/test_serialization.py::TestESCAIJSONDecoder::test_decode_set PASSED [ 85%]\ntests/unit/test_serialization.py::TestESCAIJSONDecoder::test_decode_tuple PASSED [ 85%]\ntests/unit/test_serialization.py::TestESCAIJSONDecoder::test_decode_bytes PASSED [ 85%]\ntests/unit/test_serialization.py::TestESCAIJSONDecoder::test_decode_regular_dict PASSED [ 85%]\ntests/unit/test_serialization.py::TestJSONSerialization::test_to_json_basic PASSED [ 86%]\ntests/unit/test_serialization.py::TestJSONSerialization::test_to_json_with_datetime PASSED [ 86%]\ntests/unit/test_serialization.py::TestJSONSerialization::test_to_json_with_indent PASSED [ 86%]\ntests/unit/test_serialization.py::TestJSONSerialization::test_to_json_serialization_error PASSED [ 86%]\ntests/unit/test_serialization.py::TestJSONSerialization::test_from_json_basic PASSED [ 86%]\ntests/unit/test_serialization.py::TestJSONSerialization::test_from_json_with_custom_decoder PASSED [ 86%]\ntests/unit/test_serialization.py::TestJSONSerialization::test_from_json_deserialization_error PASSED [ 86%]\ntests/unit/test_serialization.py::TestDictSerialization::test_to_dict_basic PASSED [ 87%]\ntests/unit/test_serialization.py::TestDictSerialization::test_to_dict_with_model PASSED [ 87%]\ntests/unit/test_serialization.py::TestDictSerialization::test_to_dict_with_datetime PASSED [ 87%]\ntests/unit/test_serialization.py::TestDictSerialization::test_to_dict_with_enum PASSED [ 87%]\ntests/unit/test_serialization.py::TestDictSerialization::test_to_dict_with_collections PASSED [ 87%]\ntests/unit/test_serialization.py::TestDictSerialization::test_to_dict_with_nested_object PASSED [ 87%]\ntests/unit/test_serialization.py::TestDictSerialization::test_to_dict_max_depth PASSED [ 87%]\ntests/unit/test_serialization.py::TestDictSerialization::test_to_dict_include_private PASSED [ 88%]\ntests/unit/test_serialization.py::TestDictSerialization::test_from_dict_with_model PASSED [ 88%]\ntests/unit/test_serialization.py::TestDictSerialization::test_from_dict_serialization_error PASSED [ 88%]\ntests/unit/test_serialization.py::TestPickleSerialization::test_to_pickle_basic PASSED [ 88%]\ntests/unit/test_serialization.py::TestPickleSerialization::test_to_pickle_with_objects PASSED [ 88%]\ntests/unit/test_serialization.py::TestPickleSerialization::test_from_pickle_basic PASSED [ 88%]\ntests/unit/test_serialization.py::TestPickleSerialization::test_pickle_serialization_error PASSED [ 88%]\ntests/unit/test_serialization.py::TestPickleSerialization::test_pickle_deserialization_error PASSED [ 89%]\ntests/unit/test_serialization.py::TestBatchSerialization::test_serialize_batch_json PASSED [ 89%]\ntests/unit/test_serialization.py::TestBatchSerialization::test_serialize_batch_pickle PASSED [ 89%]\ntests/unit/test_serialization.py::TestBatchSerialization::test_serialize_batch_invalid_format PASSED [ 89%]\ntests/unit/test_serialization.py::TestBatchSerialization::test_deserialize_batch_json PASSED [ 89%]\ntests/unit/test_serialization.py::TestBatchSerialization::test_deserialize_batch_pickle PASSED [ 89%]\ntests/unit/test_serialization.py::TestBatchSerialization::test_deserialize_batch_invalid_format PASSED [ 90%]\ntests/unit/test_serialization.py::TestBatchSerialization::test_deserialize_batch_non_list PASSED [ 90%]\ntests/unit/test_serialization.py::TestSerializationRegistry::test_register_serializer PASSED [ 90%]\ntests/unit/test_serialization.py::TestSerializationRegistry::test_register_deserializer PASSED [ 90%]\ntests/unit/test_serialization.py::TestSerializationRegistry::test_serialize_unregistered_type PASSED [ 90%]\ntests/unit/test_serialization.py::TestSerializationRegistry::test_deserialize_unregistered_type PASSED [ 90%]\ntests/unit/test_serialization.py::TestSafeSerialization::test_safe_serialize_json_success PASSED [ 90%]\ntests/unit/test_serialization.py::TestSafeSerialization::test_safe_serialize_pickle_success PASSED [ 91%]\ntests/unit/test_serialization.py::TestSafeSerialization::test_safe_serialize_fallback_to_str PASSED [ 91%]\ntests/unit/test_serialization.py::TestSafeSerialization::test_safe_serialize_no_fallback PASSED [ 91%]\ntests/unit/test_serialization.py::TestSafeSerialization::test_safe_serialize_invalid_format PASSED [ 91%]\ntests/unit/test_statistical_analysis.py::TestStatisticalTest::test_creation PASSED [ 91%]\ntests/unit/test_statistical_analysis.py::TestHypothesisTest::test_creation PASSED [ 91%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_initialization PASSED [ 91%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_compare_behavioral_patterns ERROR [ 92%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_analyze_pattern_significance ERROR [ 92%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_correlation_analysis ERROR [ 92%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_time_series_analysis FAILED [ 92%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_granger_causality_analysis FAILED [ 92%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_multiple_comparison_correction PASSED [ 92%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_power_analysis FAILED [ 92%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_check_assumptions FAILED [ 93%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_independent_t_test FAILED [ 93%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_mann_whitney_test FAILED [ 93%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_extract_epistemic_features ERROR [ 93%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_interpret_test_result PASSED [ 93%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_assess_practical_significance PASSED [ 93%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_interpret_correlation PASSED [ 93%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_correlation_confidence_interval PASSED [ 94%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_holm_correction PASSED [ 94%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_benjamini_hochberg_correction PASSED [ 94%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalysisIntegration::test_complete_pattern_comparison_workflow ERROR [ 94%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalysisIntegration::test_correlation_analysis_workflow ERROR [ 94%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalysisIntegration::test_multiple_testing_workflow PASSED [ 94%]\ntests/unit/test_statistical_analysis.py::TestStatisticalAnalysisIntegration::test_statistical_power_workflow FAILED [ 95%]\ntests/unit/test_validation.py::TestValidationError::test_validation_error_creation PASSED [ 95%]\ntests/unit/test_validation.py::TestValidationError::test_validation_error_format_message PASSED [ 95%]\ntests/unit/test_validation.py::TestStringValidation::test_validate_string_valid PASSED [ 95%]\ntests/unit/test_validation.py::TestStringValidation::test_validate_string_invalid_type PASSED [ 95%]\ntests/unit/test_validation.py::TestStringValidation::test_validate_string_empty PASSED [ 95%]\ntests/unit/test_validation.py::TestStringValidation::test_validate_string_length_constraints PASSED [ 95%]\ntests/unit/test_validation.py::TestStringValidation::test_validate_string_pattern PASSED [ 96%]\ntests/unit/test_validation.py::TestNumberValidation::test_validate_number_valid PASSED [ 96%]\ntests/unit/test_validation.py::TestNumberValidation::test_validate_number_invalid_type PASSED [ 96%]\ntests/unit/test_validation.py::TestNumberValidation::test_validate_number_type_restrictions PASSED [ 96%]\ntests/unit/test_validation.py::TestNumberValidation::test_validate_number_range_constraints PASSED [ 96%]\ntests/unit/test_validation.py::TestProbabilityValidation::test_validate_probability_valid PASSED [ 96%]\ntests/unit/test_validation.py::TestProbabilityValidation::test_validate_probability_invalid PASSED [ 96%]\ntests/unit/test_validation.py::TestDatetimeValidation::test_validate_datetime_valid PASSED [ 97%]\ntests/unit/test_validation.py::TestDatetimeValidation::test_validate_datetime_invalid_type PASSED [ 97%]\ntests/unit/test_validation.py::TestDatetimeValidation::test_validate_datetime_time_constraints PASSED [ 97%]\ntests/unit/test_validation.py::TestListValidation::test_validate_list_valid PASSED [ 97%]\ntests/unit/test_validation.py::TestListValidation::test_validate_list_invalid_type PASSED [ 97%]\ntests/unit/test_validation.py::TestListValidation::test_validate_list_length_constraints PASSED [ 97%]\ntests/unit/test_validation.py::TestListValidation::test_validate_list_item_validation PASSED [ 97%]\ntests/unit/test_validation.py::TestDictValidation::test_validate_dict_valid PASSED [ 98%]\ntests/unit/test_validation.py::TestDictValidation::test_validate_dict_invalid_type PASSED [ 98%]\ntests/unit/test_validation.py::TestDictValidation::test_validate_dict_required_keys PASSED [ 98%]\ntests/unit/test_validation.py::TestDictValidation::test_validate_dict_optional_keys PASSED [ 98%]\ntests/unit/test_validation.py::TestEnumValidation::test_validate_enum_valid PASSED [ 98%]\ntests/unit/test_validation.py::TestEnumValidation::test_validate_enum_invalid PASSED [ 98%]\ntests/unit/test_validation.py::TestIdValidation::test_validate_id_valid PASSED [ 98%]\ntests/unit/test_validation.py::TestIdValidation::test_validate_id_invalid PASSED [ 99%]\ntests/unit/test_validation.py::TestValidationContext::test_validation_context_no_errors PASSED [ 99%]\ntests/unit/test_validation.py::TestValidationContext::test_validation_context_with_errors PASSED [ 99%]\ntests/unit/test_validation.py::TestValidationContext::test_validation_context_has_errors PASSED [ 99%]\ntests/unit/test_validation.py::TestModelInstanceValidation::test_validate_model_instance_valid PASSED [ 99%]\ntests/unit/test_validation.py::TestModelInstanceValidation::test_validate_model_instance_wrong_type PASSED [ 99%]\ntests/unit/test_validation.py::TestModelInstanceValidation::test_validate_model_instance_invalid_validation PASSED [100%]\n\n=================================== ERRORS ====================================\n__ ERROR at setup of TestFailurePatternDetector.test_detect_failure_patterns __\ntests\\unit\\test_failure_analysis.py:28: in failed_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_ ERROR at setup of TestFailurePatternDetector.test_identify_failure_signatures _\ntests\\unit\\test_failure_analysis.py:28: in failed_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_ ERROR at setup of TestFailurePatternDetector.test_extract_failure_features __\ntests\\unit\\test_failure_analysis.py:28: in failed_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_ ERROR at setup of TestFailurePatternDetector.test_extract_cluster_signature _\ntests\\unit\\test_failure_analysis.py:28: in failed_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_ ERROR at setup of TestFailurePatternDetector.test_analyze_failure_characteristics _\ntests\\unit\\test_failure_analysis.py:28: in failed_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n______ ERROR at setup of TestRootCauseAnalyzer.test_analyze_root_causes _______\ntests\\unit\\test_failure_analysis.py:28: in failed_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n______ ERROR at setup of TestRootCauseAnalyzer.test_prepare_causal_data _______\ntests\\unit\\test_failure_analysis.py:28: in failed_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n____ ERROR at setup of TestRootCauseAnalyzer.test_extract_causal_features _____\ntests\\unit\\test_failure_analysis.py:28: in failed_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n______ ERROR at setup of TestFailureAnalysisEngine.test_analyze_failures ______\ntests\\unit\\test_failure_analysis.py:28: in failed_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_ ERROR at setup of TestFailureAnalysisEngine.test_calculate_failure_severity _\ntests\\unit\\test_failure_analysis.py:28: in failed_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n__ ERROR at setup of TestFailureAnalysisEngine.test_extract_common_triggers ___\ntests\\unit\\test_failure_analysis.py:28: in failed_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_ ERROR at setup of TestFailureAnalysisIntegration.test_end_to_end_failure_analysis _\ntests\\unit\\test_failure_analysis.py:28: in failed_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_ ERROR at setup of TestFailureAnalysisIntegration.test_pattern_detection_with_real_clustering _\ntests\\unit\\test_failure_analysis.py:28: in failed_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_ ERROR at setup of TestFailureAnalysisIntegration.test_failure_signature_analysis _\ntests\\unit\\test_failure_analysis.py:28: in failed_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_ ERROR at setup of TestFailureAnalysisIntegration.test_root_cause_analysis_with_real_data _\ntests\\unit\\test_failure_analysis.py:28: in failed_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n______ ERROR at setup of TestModelEvaluator.test_evaluate_ensemble_model ______\ntests\\unit\\test_model_evaluation.py:52: in sample_sequences\n    steps = [\ntests\\unit\\test_model_evaluation.py:53: in <listcomp>\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_______ ERROR at setup of TestModelEvaluator.test_evaluate_online_model _______\ntests\\unit\\test_model_evaluation.py:52: in sample_sequences\n    steps = [\ntests\\unit\\test_model_evaluation.py:53: in <listcomp>\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_ ERROR at setup of TestModelEvaluationIntegration.test_complete_evaluation_workflow _\ntests\\unit\\test_model_evaluation.py:52: in sample_sequences\n    steps = [\ntests\\unit\\test_model_evaluation.py:53: in <listcomp>\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n__________ ERROR at setup of TestPrefixSpanMiner.test_mine_patterns ___________\ntests\\unit\\test_pattern_mining.py:24: in sample_execution_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n____ ERROR at setup of TestPrefixSpanMiner.test_convert_to_item_sequences _____\ntests\\unit\\test_pattern_mining.py:24: in sample_execution_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_____________ ERROR at setup of TestSPADEMiner.test_mine_patterns _____________\ntests\\unit\\test_pattern_mining.py:24: in sample_execution_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n________ ERROR at setup of TestSPADEMiner.test_build_vertical_database ________\ntests\\unit\\test_pattern_mining.py:24: in sample_execution_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_______ ERROR at setup of TestSPADEMiner.test_find_frequent_1_sequences _______\ntests\\unit\\test_pattern_mining.py:24: in sample_execution_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n___ ERROR at setup of TestPatternMiningEngine.test_mine_behavioral_patterns ___\ntests\\unit\\test_pattern_mining.py:24: in sample_execution_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_ ERROR at setup of TestPatternMiningIntegration.test_end_to_end_pattern_mining _\ntests\\unit\\test_pattern_mining.py:24: in sample_execution_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_ ERROR at setup of TestPatternMiningIntegration.test_pattern_mining_performance _\ntests\\unit\\test_pattern_mining.py:24: in sample_execution_sequences\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_____________ ERROR at setup of TestEnsemblePredictor.test_train ______________\ntests\\unit\\test_prediction_models.py:41: in sample_sequences\n    steps = [\ntests\\unit\\test_prediction_models.py:42: in <listcomp>\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n________ ERROR at setup of TestEnsemblePredictor.test_prepare_features ________\ntests\\unit\\test_prediction_models.py:41: in sample_sequences\n    steps = [\ntests\\unit\\test_prediction_models.py:42: in <listcomp>\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n___ ERROR at setup of TestEnsemblePredictor.test_extract_sequence_features ____\ntests\\unit\\test_prediction_models.py:41: in sample_sequences\n    steps = [\ntests\\unit\\test_prediction_models.py:42: in <listcomp>\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n____ ERROR at setup of TestEnsemblePredictor.test_extract_static_features _____\ntests\\unit\\test_prediction_models.py:41: in sample_sequences\n    steps = [\ntests\\unit\\test_prediction_models.py:42: in <listcomp>\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_____ ERROR at setup of TestEnsemblePredictor.test_identify_risk_factors ______\ntests\\unit\\test_prediction_models.py:41: in sample_sequences\n    steps = [\ntests\\unit\\test_prediction_models.py:42: in <listcomp>\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_ ERROR at setup of TestPredictionModelsIntegration.test_ensemble_prediction_workflow _\ntests\\unit\\test_prediction_models.py:41: in sample_sequences\n    steps = [\ntests\\unit\\test_prediction_models.py:42: in <listcomp>\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_ ERROR at setup of TestPredictionModelsIntegration.test_online_learning_workflow _\ntests\\unit\\test_prediction_models.py:41: in sample_sequences\n    steps = [\ntests\\unit\\test_prediction_models.py:42: in <listcomp>\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_ ERROR at setup of TestStatisticalAnalyzer.test_compare_behavioral_patterns __\ntests\\unit\\test_statistical_analysis.py:30: in sample_behavioral_pattern1\n    steps = [\ntests\\unit\\test_statistical_analysis.py:31: in <listcomp>\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_ ERROR at setup of TestStatisticalAnalyzer.test_analyze_pattern_significance _\ntests\\unit\\test_statistical_analysis.py:30: in sample_behavioral_pattern1\n    steps = [\ntests\\unit\\test_statistical_analysis.py:31: in <listcomp>\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_____ ERROR at setup of TestStatisticalAnalyzer.test_correlation_analysis _____\ntests\\unit\\test_statistical_analysis.py:109: in sample_epistemic_states\n    BeliefState(\nE   TypeError: BeliefState.__init__() got an unexpected keyword argument 'belief_id'\n__ ERROR at setup of TestStatisticalAnalyzer.test_extract_epistemic_features __\ntests\\unit\\test_statistical_analysis.py:109: in sample_epistemic_states\n    BeliefState(\nE   TypeError: BeliefState.__init__() got an unexpected keyword argument 'belief_id'\n_ ERROR at setup of TestStatisticalAnalysisIntegration.test_complete_pattern_comparison_workflow _\ntests\\unit\\test_statistical_analysis.py:30: in sample_behavioral_pattern1\n    steps = [\ntests\\unit\\test_statistical_analysis.py:31: in <listcomp>\n    ExecutionStep(\nE   TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\n_ ERROR at setup of TestStatisticalAnalysisIntegration.test_correlation_analysis_workflow _\ntests\\unit\\test_statistical_analysis.py:109: in sample_epistemic_states\n    BeliefState(\nE   TypeError: BeliefState.__init__() got an unexpected keyword argument 'belief_id'\n================================== FAILURES ===================================\n________ TestCausalEngine.test_discover_relationships_temporal_pattern ________\ntests\\unit\\test_causal_engine.py:365: in test_discover_relationships_temporal_pattern\n    assert len(relationships) > 0\nE   assert 0 > 0\nE    +  where 0 = len([])\n______________ TestEpistemicExtractor.test_calculate_confidence _______________\ntests\\unit\\test_epistemic_extractor.py:111: in test_calculate_confidence\n    assert confidence2 > 0.8\nE   assert 0.5372916460037231 > 0.8\n---------------------------- Captured stderr setup ----------------------------\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nDevice set to use cpu\n___________ TestEpistemicExtractor.test_confidence_score_extraction ___________\ntests\\unit\\test_epistemic_extractor.py:154: in test_confidence_score_extraction\n    assert score3 == 0.7  # Default for belief statements\n    ^^^^^^^^^^^^^^^^^^^^\nE   assert 0.5160086750984192 == 0.7\n---------------------------- Captured stderr setup ----------------------------\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nDevice set to use cpu\n___________ TestEpistemicExtractor.test_shannon_entropy_calculation ___________\ntests\\unit\\test_epistemic_extractor.py:295: in test_shannon_entropy_calculation\n    assert entropy > 0\nE   assert -0.0 > 0\n---------------------------- Captured stderr setup ----------------------------\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nDevice set to use cpu\n_______________________ TestExceptions.test_api_errors ________________________\ntests\\unit\\test_error_handling.py:85: in test_api_errors\n    auth_error = AuthenticationError(\"Invalid token\")\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nescai_framework\\utils\\exceptions.py:263: in __init__\n    super().__init__(\nescai_framework\\utils\\exceptions.py:251: in __init__\n    super().__init__(\nE   TypeError: escai_framework.utils.exceptions.ESCAIBaseException.__init__() got multiple values for keyword argument 'category'\n________________ TestRetryMechanism.test_async_retry_exhausted ________________\ntests\\unit\\test_error_handling.py:159: in test_async_retry_exhausted\n    await retry_manager.execute_async(always_fails)\nescai_framework\\utils\\retry.py:112: in execute_async\n    raise e\nescai_framework\\utils\\retry.py:102: in execute_async\n    result = await func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests\\unit\\test_error_handling.py:153: in always_fails\n    raise ConnectionError(\"Always fails\")\nE   ConnectionError: Always fails\n------------------------------ Captured log call ------------------------------\nWARNING  escai_framework.utils.retry:retry.py:116 Attempt 1 failed for always_fails: Always fails. Retrying in 0.01 seconds...\nWARNING  escai_framework.utils.retry:retry.py:116 Attempt 2 failed for always_fails: Always fails. Retrying in 0.02 seconds...\nERROR    escai_framework.utils.retry:retry.py:111 Non-retryable error in always_fails: Always fails\n_________ TestFallbackMechanisms.test_rule_based_epistemic_extractor __________\ntests\\unit\\test_error_handling.py:296: in test_rule_based_epistemic_extractor\n    assert result.success\nE   assert False\nE    +  where False = FallbackResult(success=False, result=None, strategy_used=<FallbackStrategy.RULE_BASED: 'rule_based'>, confidence=0.0, error_message=\"BeliefState.__init__() missing 1 required positional argument: 'belief_type'\").success\n------------------------------ Captured log call ------------------------------\nERROR    escai_framework.utils.fallback:fallback.py:160 Rule-based epistemic extraction failed: BeliefState.__init__() missing 1 required positional argument: 'belief_type'\n________________ TestFallbackMechanisms.test_fallback_manager _________________\ntests\\unit\\test_error_handling.py:318: in test_fallback_manager\n    assert result.success\nE   AssertionError: assert False\nE    +  where False = FallbackResult(success=False, result=None, strategy_used=<FallbackStrategy.DEFAULT_VALUE: 'default_value'>, confidence=0.0, error_message='Primary function failed: TestFallbackMechanisms.test_fallback_manager.<locals>.failing_primary() takes 0 positional arguments but 1 was given. All fallbacks failed.').success\n------------------------------ Captured log call ------------------------------\nWARNING  escai_framework.utils.fallback:fallback.py:414 Primary function failed: TestFallbackMechanisms.test_fallback_manager.<locals>.failing_primary() takes 0 positional arguments but 1 was given. Trying fallbacks...\nERROR    escai_framework.utils.fallback:fallback.py:441 All fallback strategies failed\n________________ TestFallbackMechanisms.test_fallback_caching _________________\ntests\\unit\\test_error_handling.py:348: in test_fallback_caching\n    assert call_count == 1\nE   assert 0 == 1\n------------------------------ Captured log call ------------------------------\nWARNING  escai_framework.utils.fallback:fallback.py:414 Primary function failed: TestFallbackMechanisms.test_fallback_caching.<locals>.counting_primary() takes 0 positional arguments but 1 was given. Trying fallbacks...\nERROR    escai_framework.utils.fallback:fallback.py:441 All fallback strategies failed\nWARNING  escai_framework.utils.fallback:fallback.py:414 Primary function failed: TestFallbackMechanisms.test_fallback_caching.<locals>.counting_primary() takes 0 positional arguments but 1 was given. Trying fallbacks...\nERROR    escai_framework.utils.fallback:fallback.py:441 All fallback strategies failed\n____________________ TestErrorTracking.test_error_tracker _____________________\ntests\\unit\\test_error_handling.py:471: in test_error_tracker\n    assert \"ValueError\" in str(metrics[\"errors_by_component\"])\nE   assert 'ValueError' in \"{'comp1': 1, 'comp2': 1}\"\nE    +  where \"{'comp1': 1, 'comp2': 1}\" = str({'comp1': 1, 'comp2': 1})\n______________ TestIntegration.test_full_error_handling_pipeline ______________\ntests\\unit\\test_error_handling.py:554: in test_full_error_handling_pipeline\n    assert result.success  # Should succeed via fallback\n    ^^^^^^^^^^^^^^^^^^^^^\nE   AssertionError: assert False\nE    +  where False = FallbackResult(success=False, result=None, strategy_used=<FallbackStrategy.DEFAULT_VALUE: 'default_value'>, confidence=0.0, error_message='Primary function failed: Simulated processing failure. All fallbacks failed.').success\n------------------------------ Captured log call ------------------------------\nWARNING  escai_framework.utils.fallback:fallback.py:414 Primary function failed: Simulated processing failure. Trying fallbacks...\nERROR    escai_framework.utils.fallback:fallback.py:347 Baseline prediction failed: PredictionResult.__init__() got an unexpected keyword argument 'confidence'\nWARNING  escai_framework.utils.fallback:fallback.py:434 Fallback provider BaselinePredictor failed\nERROR    escai_framework.utils.fallback:fallback.py:441 All fallback strategies failed\n_______________ TestIntegration.test_circuit_breaker_with_retry _______________\ntests\\unit\\test_error_handling.py:577: in test_circuit_breaker_with_retry\n    await retry_manager.execute_async(\nescai_framework\\utils\\retry.py:112: in execute_async\n    raise e\nescai_framework\\utils\\retry.py:102: in execute_async\n    result = await func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\nescai_framework\\utils\\circuit_breaker.py:212: in call_async\n    raise ServiceUnavailableError(\nE   escai_framework.utils.exceptions.ServiceUnavailableError: Service 'Circuit breaker 'integration_test' is open' is unavailable (HTTP 503)\n------------------------------ Captured log call ------------------------------\nWARNING  escai_framework.utils.retry:retry.py:116 Attempt 1 failed for <lambda>: Service down. Retrying in 0.01 seconds...\nWARNING  escai_framework.utils.circuit_breaker:circuit_breaker.py:186 Circuit breaker 'integration_test' opened. Failures: 2, Failure rate: 100.00%\nWARNING  escai_framework.utils.retry:retry.py:116 Attempt 2 failed for <lambda>: Service down. Retrying in 0.02 seconds...\nERROR    escai_framework.utils.retry:retry.py:111 Non-retryable error in <lambda>: Service 'Circuit breaker 'integration_test' is open' is unavailable (HTTP 503)\n________________ TestModelEvaluator.test_cross_validate_model _________________\ntests\\unit\\test_model_evaluation.py:284: in test_cross_validate_model\n    result = await model_evaluator.cross_validate_model(\nescai_framework\\analytics\\model_evaluation.py:273: in cross_validate_model\n    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218: in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:677: in cross_val_score\n    cv_results = cross_validate(\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218: in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:346: in cross_validate\n    cv = check_cv(cv, y, classifier=is_classifier(estimator))\n                                    ^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1211: in is_classifier\n    return get_tags(estimator).estimator_type == \"classifier\"\n           ^^^^^^^^^^^^^^^^^^^\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:325: in get_tags\n    tags = estimator.__sklearn_tags__()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\unittest\\mock.py:655: in __getattr__\n    raise AttributeError(name)\nE   AttributeError: __sklearn_tags__\n________________ TestModelEvaluator.test_hyperparameter_tuning ________________\ntests\\unit\\test_model_evaluation.py:340: in test_hyperparameter_tuning\n    result = await model_evaluator.hyperparameter_tuning(\nescai_framework\\analytics\\model_evaluation.py:333: in hyperparameter_tuning\n    search = GridSearchCV(\nE   TypeError: GridSearchCV.__init__() got an unexpected keyword argument 'random_state'\n________ TestModelEvaluationIntegration.test_model_comparison_workflow ________\ntests\\unit\\test_model_evaluation.py:543: in test_model_comparison_workflow\n    results = await evaluator.compare_models(models, X, y)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nescai_framework\\analytics\\model_evaluation.py:309: in compare_models\n    cv_results = await self.cross_validate_model(model, X, y, scoring)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nescai_framework\\analytics\\model_evaluation.py:273: in cross_validate_model\n    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218: in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:677: in cross_val_score\n    cv_results = cross_validate(\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218: in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:346: in cross_validate\n    cv = check_cv(cv, y, classifier=is_classifier(estimator))\n                                    ^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1211: in is_classifier\n    return get_tags(estimator).estimator_type == \"classifier\"\n           ^^^^^^^^^^^^^^^^^^^\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_tags.py:325: in get_tags\n    tags = estimator.__sklearn_tags__()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\unittest\\mock.py:655: in __getattr__\n    raise AttributeError(name)\nE   AttributeError: __sklearn_tags__\n__ TestModelEvaluationIntegration.test_hyperparameter_optimization_workflow ___\ntests\\unit\\test_model_evaluation.py:581: in test_hyperparameter_optimization_workflow\n    result = await evaluator.hyperparameter_tuning(\nescai_framework\\analytics\\model_evaluation.py:333: in hyperparameter_tuning\n    search = GridSearchCV(\nE   TypeError: GridSearchCV.__init__() got an unexpected keyword argument 'random_state'\n____________ TestNeo4jManagerConnection.test_successful_connection ____________\ntests\\unit\\test_neo4j_manager.py:110: in test_successful_connection\n    await manager.connect()\nescai_framework\\storage\\neo4j_manager.py:62: in connect\n    await self._initialize_schema()\nescai_framework\\storage\\neo4j_manager.py:96: in _initialize_schema\n    async with self.driver.session(database=self.database) as session:\nE   TypeError: 'coroutine' object does not support the asynchronous context manager protocol\n------------------------------ Captured log call ------------------------------\nERROR    escai_framework.storage.neo4j_manager:neo4j_manager.py:68 Unexpected error connecting to Neo4j: 'coroutine' object does not support the asynchronous context manager protocol\n___________ TestNeo4jManagerNodeOperations.test_create_node_success ___________\ntests\\unit\\test_neo4j_manager.py:171: in test_create_node_success\n    assert success is True\nE   assert False is True\n------------------------------ Captured log call ------------------------------\nERROR    escai_framework.storage.neo4j_manager:neo4j_manager.py:128 Failed to create node test_node_001: 'coroutine' object does not support the asynchronous context manager protocol\n___________ TestNeo4jManagerNodeOperations.test_create_node_failure ___________\ntests\\unit\\test_neo4j_manager.py:188: in test_create_node_failure\n    manager.driver.session.return_value.__aenter__.return_value = mock_session\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'method' object has no attribute 'return_value'\n__________ TestNeo4jManagerNodeOperations.test_create_node_no_result __________\ntests\\unit\\test_neo4j_manager.py:204: in test_create_node_no_result\n    manager.driver.session.return_value.__aenter__.return_value = mock_session\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'method' object has no attribute 'return_value'\n___ TestNeo4jManagerRelationshipOperations.test_create_relationship_success ___\ntests\\unit\\test_neo4j_manager.py:230: in test_create_relationship_success\n    manager.driver.session.return_value.__aenter__.return_value = mock_session\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'method' object has no attribute 'return_value'\n___ TestNeo4jManagerRelationshipOperations.test_create_relationship_failure ___\ntests\\unit\\test_neo4j_manager.py:266: in test_create_relationship_failure\n    manager.driver.session.return_value.__aenter__.return_value = mock_session\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'method' object has no attribute 'return_value'\n_______ TestNeo4jManagerQueryOperations.test_find_causal_paths_success ________\ntests\\unit\\test_neo4j_manager.py:310: in test_find_causal_paths_success\n    manager.driver.session.return_value.__aenter__.return_value = mock_session\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'method' object has no attribute 'return_value'\n_____ TestNeo4jManagerQueryOperations.test_find_causal_paths_empty_result _____\ntests\\unit\\test_neo4j_manager.py:334: in test_find_causal_paths_empty_result\n    manager.driver.session.return_value.__aenter__.return_value = mock_session\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'method' object has no attribute 'return_value'\n______ TestNeo4jManagerQueryOperations.test_get_node_centrality_success _______\ntests\\unit\\test_neo4j_manager.py:360: in test_get_node_centrality_success\n    manager.driver.session.return_value.__aenter__.return_value = mock_session\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'method' object has no attribute 'return_value'\n______ TestNeo4jManagerQueryOperations.test_execute_custom_query_success ______\ntests\\unit\\test_neo4j_manager.py:389: in test_execute_custom_query_success\n    manager.driver.session.return_value.__aenter__.return_value = mock_session\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'method' object has no attribute 'return_value'\n__________ TestNeo4jManagerQueryOperations.test_delete_node_success ___________\ntests\\unit\\test_neo4j_manager.py:413: in test_delete_node_success\n    manager.driver.session.return_value.__aenter__.return_value = mock_session\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'method' object has no attribute 'return_value'\n______ TestNeo4jManagerQueryOperations.test_get_graph_statistics_success ______\ntests\\unit\\test_neo4j_manager.py:441: in test_get_graph_statistics_success\n    manager.driver.session.return_value.__aenter__.return_value = mock_session\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'method' object has no attribute 'return_value'\n___ TestNeo4jManagerAnalysisOperations.test_analyze_causal_patterns_success ___\ntests\\unit\\test_neo4j_manager.py:506: in test_analyze_causal_patterns_success\n    manager.driver.session.return_value.__aenter__.return_value = mock_session\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'method' object has no attribute 'return_value'\n___ TestNeo4jManagerAnalysisOperations.test_analyze_causal_patterns_failure ___\ntests\\unit\\test_neo4j_manager.py:526: in test_analyze_causal_patterns_failure\n    manager.driver.session.return_value.__aenter__.return_value = mock_session\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'method' object has no attribute 'return_value'\n____ TestNeo4jManagerErrorHandling.test_query_execution_exception_handling ____\ntests\\unit\\test_neo4j_manager.py:680: in test_query_execution_exception_handling\n    manager.driver.session.return_value.__aenter__.return_value = mock_session\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'method' object has no attribute 'return_value'\n_____________________ TestLSTMPredictor.test_forward_pass _____________________\ntests\\unit\\test_prediction_models.py:154: in test_forward_pass\n    assert torch.all(output >= 0) and torch.all(output <= 1)  # Sigmoid output\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   assert (tensor(False))\nE    +  where tensor(False) = <built-in method all of type object at 0x00007FFD4A027450>(tensor([[-0.1611, -0.1368],\\n        [-0.1125, -0.0697],\\n        [-0.2138,  0.0176],\\n        [-0.0832, -0.1447]], grad_fn=<AddmmBackward0>) >= 0)\nE    +    where <built-in method all of type object at 0x00007FFD4A027450> = torch.all\n_______________ TestOnlineLearningPredictor.test_initialization _______________\ntests\\unit\\test_prediction_models.py:298: in test_initialization\n    predictor = OnlineLearningPredictor()\n                ^^^^^^^^^^^^^^^^^^^^^^^^^\nescai_framework\\analytics\\prediction_models.py:546: in __init__\n    self.classifier = ensemble.AdaptiveRandomForestClassifier(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: module 'river.ensemble' has no attribute 'AdaptiveRandomForestClassifier'\n________________ TestOnlineLearningPredictor.test_learn_online ________________\ntests\\unit\\test_prediction_models.py:308: in test_learn_online\n    predictor = OnlineLearningPredictor()\n                ^^^^^^^^^^^^^^^^^^^^^^^^^\nescai_framework\\analytics\\prediction_models.py:546: in __init__\n    self.classifier = ensemble.AdaptiveRandomForestClassifier(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: module 'river.ensemble' has no attribute 'AdaptiveRandomForestClassifier'\n_______________ TestOnlineLearningPredictor.test_predict_online _______________\ntests\\unit\\test_prediction_models.py:326: in test_predict_online\n    predictor = OnlineLearningPredictor()\n                ^^^^^^^^^^^^^^^^^^^^^^^^^\nescai_framework\\analytics\\prediction_models.py:546: in __init__\n    self.classifier = ensemble.AdaptiveRandomForestClassifier(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: module 'river.ensemble' has no attribute 'AdaptiveRandomForestClassifier'\n____________ TestOnlineLearningPredictor.test_detect_concept_drift ____________\ntests\\unit\\test_prediction_models.py:350: in test_detect_concept_drift\n    predictor = OnlineLearningPredictor()\n                ^^^^^^^^^^^^^^^^^^^^^^^^^\nescai_framework\\analytics\\prediction_models.py:546: in __init__\n    self.classifier = ensemble.AdaptiveRandomForestClassifier(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: module 'river.ensemble' has no attribute 'AdaptiveRandomForestClassifier'\n_______________ TestOnlineLearningPredictor.test_adapt_to_drift _______________\ntests\\unit\\test_prediction_models.py:366: in test_adapt_to_drift\n    predictor = OnlineLearningPredictor()\n                ^^^^^^^^^^^^^^^^^^^^^^^^^\nescai_framework\\analytics\\prediction_models.py:546: in __init__\n    self.classifier = ensemble.AdaptiveRandomForestClassifier(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: module 'river.ensemble' has no attribute 'AdaptiveRandomForestClassifier'\n_______________ TestHyperparameterTuner.test_tune_random_forest _______________\ntests\\unit\\test_prediction_models.py:412: in test_tune_random_forest\n    assert result['best_params'] == {'n_estimators': 100, 'max_depth': 10}\nE   AssertionError: assert {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100} == {'n_estimators': 100, 'max_depth': 10}\nE     \nE     Common items:\nE     {'n_estimators': 100}\nE     Differing items:\nE     {'max_depth': None} != {'max_depth': 10}\nE     Left contains 2 more items:\nE     {'min_samples_leaf': 1, 'min_samples_split': 5}\nE     \nE     Full diff:\nE       {\nE     -     'max_depth': 10,\nE     ?                  ^^\nE     +     'max_depth': None,\nE     ?                  ^^^^\nE     +     'min_samples_leaf': 1,\nE     +     'min_samples_split': 5,\nE           'n_estimators': 100,\nE       }\n__________________ TestHyperparameterTuner.test_tune_xgboost __________________\ntests\\unit\\test_prediction_models.py:436: in test_tune_xgboost\n    assert result['best_params'] == {'n_estimators': 200, 'learning_rate': 0.1}\nE   AssertionError: assert {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8} == {'n_estimators': 200, 'learning_rate': 0.1}\nE     \nE     Differing items:\nE     {'n_estimators': 50} != {'n_estimators': 200}\nE     {'learning_rate': 0.01} != {'learning_rate': 0.1}\nE     Left contains 2 more items:\nE     {'max_depth': 3, 'subsample': 0.8}\nE     \nE     Full diff:\nE       {\nE     -     'learning_rate': 0.1,\nE     +     'learning_rate': 0.01,\nE     ?                        +\nE     +     'max_depth': 3,\nE     -     'n_estimators': 200,\nE     ?                     ^^\nE     +     'n_estimators': 50,\nE     ?                     ^\nE     +     'subsample': 0.8,\nE       }\n______________ TestStatisticalAnalyzer.test_time_series_analysis ______________\ntests\\unit\\test_statistical_analysis.py:313: in test_time_series_analysis\n    with patch.object(statistical_analyzer, '_mann_kendall_trend_test') as mock_trend, \\\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\unittest\\mock.py:1446: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\unittest\\mock.py:1419: in get_original\n    raise AttributeError(\nE   AttributeError: <escai_framework.analytics.statistical_analysis.StatisticalAnalyzer object at 0x000001910E31D750> does not have the attribute '_mann_kendall_trend_test'\n___________ TestStatisticalAnalyzer.test_granger_causality_analysis ___________\ntests\\unit\\test_statistical_analysis.py:355: in test_granger_causality_analysis\n    with patch('statsmodels.tsa.stattools.granger_causality_test') as mock_granger:\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\unittest\\mock.py:1446: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\unittest\\mock.py:1419: in get_original\n    raise AttributeError(\nE   AttributeError: <module 'statsmodels.tsa.stattools' from 'C:\\\\Users\\\\laksh\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\statsmodels\\\\tsa\\\\stattools.py'> does not have the attribute 'granger_causality_test'\n_________________ TestStatisticalAnalyzer.test_power_analysis _________________\ntests\\unit\\test_statistical_analysis.py:394: in test_power_analysis\n    with patch('statsmodels.stats.power.ttest_power') as mock_power, \\\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\unittest\\mock.py:1446: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\unittest\\mock.py:1419: in get_original\n    raise AttributeError(\nE   AttributeError: <escai_framework.analytics.statistical_analysis.StatisticalAnalyzer object at 0x000001910B233290> does not have the attribute '_calculate_required_sample_size'\n_______________ TestStatisticalAnalyzer.test_check_assumptions ________________\ntests\\unit\\test_statistical_analysis.py:434: in test_check_assumptions\n    assert assumptions['normality'] is True\nE   assert True is True\n_______________ TestStatisticalAnalyzer.test_independent_t_test _______________\ntests\\unit\\test_statistical_analysis.py:447: in test_independent_t_test\n    result = await statistical_analyzer._independent_t_test(group1, group2)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nescai_framework\\analytics\\statistical_analysis.py:401: in _independent_t_test\n    interpretation=self._interpret_t_test(t_stat, p_value, cohens_d),\n                   ^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'StatisticalAnalyzer' object has no attribute '_interpret_t_test'\n_______________ TestStatisticalAnalyzer.test_mann_whitney_test ________________\ntests\\unit\\test_statistical_analysis.py:465: in test_mann_whitney_test\n    result = await statistical_analyzer._mann_whitney_test(group1, group2)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nescai_framework\\analytics\\statistical_analysis.py:420: in _mann_whitney_test\n    interpretation=self._interpret_mann_whitney(u_stat, p_value, effect_size),\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'StatisticalAnalyzer' object has no attribute '_interpret_mann_whitney'\n_____ TestStatisticalAnalysisIntegration.test_statistical_power_workflow ______\ntests\\unit\\test_statistical_analysis.py:672: in test_statistical_power_workflow\n    result = await analyzer.power_analysis(\nescai_framework\\analytics\\statistical_analysis.py:353: in power_analysis\n    required_n = self._calculate_required_sample_size(effect_size, alpha, 0.8)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'StatisticalAnalyzer' object has no attribute '_calculate_required_sample_size'\n============================== warnings summary ===============================\ntests\\unit\\test_base_instrumentor.py:21\n  D:\\ESCAI\\tests\\unit\\test_base_instrumentor.py:21: PytestCollectionWarning: cannot collect test class 'TestInstrumentor' because it has a __init__ constructor (from: tests/unit/test_base_instrumentor.py)\n    class TestInstrumentor(BaseInstrumentor):\n\ntests/unit/test_epistemic_extractor.py: 14 warnings\n  C:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n    warnings.warn(\n\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerConnection::test_successful_connection\n  D:\\ESCAI\\escai_framework\\storage\\neo4j_manager.py:96: RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited\n    async with self.driver.session(database=self.database) as session:\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerNodeOperations::test_create_node_success\ntests/unit/test_neo4j_manager.py::TestNeo4jManagerErrorHandling::test_session_context_manager_exception\n  D:\\ESCAI\\escai_framework\\storage\\neo4j_manager.py:120: RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited\n    async with self.driver.session(database=self.database) as session:\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_estimate_completion_time_basic\ntests/unit/test_performance_predictor.py::TestPerformancePredictor::test_error_handling_estimate_completion_time\ntests/unit/test_performance_predictor.py::TestLSTMPredictor::test_lstm_initialization\ntests/unit/test_performance_predictor.py::TestLSTMPredictor::test_lstm_forward_pass\ntests/unit/test_prediction_models.py::TestLSTMPredictor::test_forward_pass\n  C:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============================ slowest 10 durations =============================\n6.92s setup    tests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_extract_beliefs\n6.55s call     tests/unit/test_prediction_models.py::TestHyperparameterTuner::test_tune_random_forest\n6.24s setup    tests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_linguistic_confidence_analysis\n5.70s setup    tests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_goal_status_classification\n5.33s setup    tests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_confidence_score_extraction\n5.29s setup    tests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_shannon_entropy_calculation\n5.18s setup    tests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_error_handling\n5.06s setup    tests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_extract_goals\n4.94s setup    tests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_quantify_uncertainty\n4.91s setup    tests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_empty_input_handling\n=========================== short test summary info ===========================\nFAILED tests/unit/test_causal_engine.py::TestCausalEngine::test_discover_relationships_temporal_pattern - assert 0 > 0\n +  where 0 = len([])\nFAILED tests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_calculate_confidence - assert 0.5372916460037231 > 0.8\nFAILED tests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_confidence_score_extraction - assert 0.5160086750984192 == 0.7\nFAILED tests/unit/test_epistemic_extractor.py::TestEpistemicExtractor::test_shannon_entropy_calculation - assert -0.0 > 0\nFAILED tests/unit/test_error_handling.py::TestExceptions::test_api_errors - TypeError: escai_framework.utils.exceptions.ESCAIBaseException.__init__() got multiple values for keyword argument 'category'\nFAILED tests/unit/test_error_handling.py::TestRetryMechanism::test_async_retry_exhausted - ConnectionError: Always fails\nFAILED tests/unit/test_error_handling.py::TestFallbackMechanisms::test_rule_based_epistemic_extractor - assert False\n +  where False = FallbackResult(success=False, result=None, strategy_used=<FallbackStrategy.RULE_BASED: 'rule_based'>, confidence=0.0, error_message=\"BeliefState.__init__() missing 1 required positional argument: 'belief_type'\").success\nFAILED tests/unit/test_error_handling.py::TestFallbackMechanisms::test_fallback_manager - AssertionError: assert False\n +  where False = FallbackResult(success=False, result=None, strategy_used=<FallbackStrategy.DEFAULT_VALUE: 'default_value'>, confidence=0.0, error_message='Primary function failed: TestFallbackMechanisms.test_fallback_manager.<locals>.failing_primary() takes 0 positional arguments but 1 was given. All fallbacks failed.').success\nFAILED tests/unit/test_error_handling.py::TestFallbackMechanisms::test_fallback_caching - assert 0 == 1\nFAILED tests/unit/test_error_handling.py::TestErrorTracking::test_error_tracker - assert 'ValueError' in \"{'comp1': 1, 'comp2': 1}\"\n +  where \"{'comp1': 1, 'comp2': 1}\" = str({'comp1': 1, 'comp2': 1})\nFAILED tests/unit/test_error_handling.py::TestIntegration::test_full_error_handling_pipeline - AssertionError: assert False\n +  where False = FallbackResult(success=False, result=None, strategy_used=<FallbackStrategy.DEFAULT_VALUE: 'default_value'>, confidence=0.0, error_message='Primary function failed: Simulated processing failure. All fallbacks failed.').success\nFAILED tests/unit/test_error_handling.py::TestIntegration::test_circuit_breaker_with_retry - escai_framework.utils.exceptions.ServiceUnavailableError: Service 'Circuit breaker 'integration_test' is open' is unavailable (HTTP 503)\nFAILED tests/unit/test_model_evaluation.py::TestModelEvaluator::test_cross_validate_model - AttributeError: __sklearn_tags__\nFAILED tests/unit/test_model_evaluation.py::TestModelEvaluator::test_hyperparameter_tuning - TypeError: GridSearchCV.__init__() got an unexpected keyword argument 'random_state'\nFAILED tests/unit/test_model_evaluation.py::TestModelEvaluationIntegration::test_model_comparison_workflow - AttributeError: __sklearn_tags__\nFAILED tests/unit/test_model_evaluation.py::TestModelEvaluationIntegration::test_hyperparameter_optimization_workflow - TypeError: GridSearchCV.__init__() got an unexpected keyword argument 'random_state'\nFAILED tests/unit/test_neo4j_manager.py::TestNeo4jManagerConnection::test_successful_connection - TypeError: 'coroutine' object does not support the asynchronous context manager protocol\nFAILED tests/unit/test_neo4j_manager.py::TestNeo4jManagerNodeOperations::test_create_node_success - assert False is True\nFAILED tests/unit/test_neo4j_manager.py::TestNeo4jManagerNodeOperations::test_create_node_failure - AttributeError: 'method' object has no attribute 'return_value'\nFAILED tests/unit/test_neo4j_manager.py::TestNeo4jManagerNodeOperations::test_create_node_no_result - AttributeError: 'method' object has no attribute 'return_value'\nFAILED tests/unit/test_neo4j_manager.py::TestNeo4jManagerRelationshipOperations::test_create_relationship_success - AttributeError: 'method' object has no attribute 'return_value'\nFAILED tests/unit/test_neo4j_manager.py::TestNeo4jManagerRelationshipOperations::test_create_relationship_failure - AttributeError: 'method' object has no attribute 'return_value'\nFAILED tests/unit/test_neo4j_manager.py::TestNeo4jManagerQueryOperations::test_find_causal_paths_success - AttributeError: 'method' object has no attribute 'return_value'\nFAILED tests/unit/test_neo4j_manager.py::TestNeo4jManagerQueryOperations::test_find_causal_paths_empty_result - AttributeError: 'method' object has no attribute 'return_value'\nFAILED tests/unit/test_neo4j_manager.py::TestNeo4jManagerQueryOperations::test_get_node_centrality_success - AttributeError: 'method' object has no attribute 'return_value'\nFAILED tests/unit/test_neo4j_manager.py::TestNeo4jManagerQueryOperations::test_execute_custom_query_success - AttributeError: 'method' object has no attribute 'return_value'\nFAILED tests/unit/test_neo4j_manager.py::TestNeo4jManagerQueryOperations::test_delete_node_success - AttributeError: 'method' object has no attribute 'return_value'\nFAILED tests/unit/test_neo4j_manager.py::TestNeo4jManagerQueryOperations::test_get_graph_statistics_success - AttributeError: 'method' object has no attribute 'return_value'\nFAILED tests/unit/test_neo4j_manager.py::TestNeo4jManagerAnalysisOperations::test_analyze_causal_patterns_success - AttributeError: 'method' object has no attribute 'return_value'\nFAILED tests/unit/test_neo4j_manager.py::TestNeo4jManagerAnalysisOperations::test_analyze_causal_patterns_failure - AttributeError: 'method' object has no attribute 'return_value'\nFAILED tests/unit/test_neo4j_manager.py::TestNeo4jManagerErrorHandling::test_query_execution_exception_handling - AttributeError: 'method' object has no attribute 'return_value'\nFAILED tests/unit/test_prediction_models.py::TestLSTMPredictor::test_forward_pass - assert (tensor(False))\n +  where tensor(False) = <built-in method all of type object at 0x00007FFD4A027450>(tensor([[-0.1611, -0.1368],\\n        [-0.1125, -0.0697],\\n        [-0.2138,  0.0176],\\n        [-0.0832, -0.1447]], grad_fn=<AddmmBackward0>) >= 0)\n +    where <built-in method all of type object at 0x00007FFD4A027450> = torch.all\nFAILED tests/unit/test_prediction_models.py::TestOnlineLearningPredictor::test_initialization - AttributeError: module 'river.ensemble' has no attribute 'AdaptiveRandomForestClassifier'\nFAILED tests/unit/test_prediction_models.py::TestOnlineLearningPredictor::test_learn_online - AttributeError: module 'river.ensemble' has no attribute 'AdaptiveRandomForestClassifier'\nFAILED tests/unit/test_prediction_models.py::TestOnlineLearningPredictor::test_predict_online - AttributeError: module 'river.ensemble' has no attribute 'AdaptiveRandomForestClassifier'\nFAILED tests/unit/test_prediction_models.py::TestOnlineLearningPredictor::test_detect_concept_drift - AttributeError: module 'river.ensemble' has no attribute 'AdaptiveRandomForestClassifier'\nFAILED tests/unit/test_prediction_models.py::TestOnlineLearningPredictor::test_adapt_to_drift - AttributeError: module 'river.ensemble' has no attribute 'AdaptiveRandomForestClassifier'\nFAILED tests/unit/test_prediction_models.py::TestHyperparameterTuner::test_tune_random_forest - AssertionError: assert {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100} == {'n_estimators': 100, 'max_depth': 10}\n  \n  Common items:\n  {'n_estimators': 100}\n  Differing items:\n  {'max_depth': None} != {'max_depth': 10}\n  Left contains 2 more items:\n  {'min_samples_leaf': 1, 'min_samples_split': 5}\n  \n  Full diff:\n    {\n  -     'max_depth': 10,\n  ?                  ^^\n  +     'max_depth': None,\n  ?                  ^^^^\n  +     'min_samples_leaf': 1,\n  +     'min_samples_split': 5,\n        'n_estimators': 100,\n    }\nFAILED tests/unit/test_prediction_models.py::TestHyperparameterTuner::test_tune_xgboost - AssertionError: assert {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8} == {'n_estimators': 200, 'learning_rate': 0.1}\n  \n  Differing items:\n  {'n_estimators': 50} != {'n_estimators': 200}\n  {'learning_rate': 0.01} != {'learning_rate': 0.1}\n  Left contains 2 more items:\n  {'max_depth': 3, 'subsample': 0.8}\n  \n  Full diff:\n    {\n  -     'learning_rate': 0.1,\n  +     'learning_rate': 0.01,\n  ?                        +\n  +     'max_depth': 3,\n  -     'n_estimators': 200,\n  ?                     ^^\n  +     'n_estimators': 50,\n  ?                     ^\n  +     'subsample': 0.8,\n    }\nFAILED tests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_time_series_analysis - AttributeError: <escai_framework.analytics.statistical_analysis.StatisticalAnalyzer object at 0x000001910E31D750> does not have the attribute '_mann_kendall_trend_test'\nFAILED tests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_granger_causality_analysis - AttributeError: <module 'statsmodels.tsa.stattools' from 'C:\\\\Users\\\\laksh\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\statsmodels\\\\tsa\\\\stattools.py'> does not have the attribute 'granger_causality_test'\nFAILED tests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_power_analysis - AttributeError: <escai_framework.analytics.statistical_analysis.StatisticalAnalyzer object at 0x000001910B233290> does not have the attribute '_calculate_required_sample_size'\nFAILED tests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_check_assumptions - assert True is True\nFAILED tests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_independent_t_test - AttributeError: 'StatisticalAnalyzer' object has no attribute '_interpret_t_test'\nFAILED tests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_mann_whitney_test - AttributeError: 'StatisticalAnalyzer' object has no attribute '_interpret_mann_whitney'\nFAILED tests/unit/test_statistical_analysis.py::TestStatisticalAnalysisIntegration::test_statistical_power_workflow - AttributeError: 'StatisticalAnalyzer' object has no attribute '_calculate_required_sample_size'\nERROR tests/unit/test_failure_analysis.py::TestFailurePatternDetector::test_detect_failure_patterns - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_failure_analysis.py::TestFailurePatternDetector::test_identify_failure_signatures - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_failure_analysis.py::TestFailurePatternDetector::test_extract_failure_features - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_failure_analysis.py::TestFailurePatternDetector::test_extract_cluster_signature - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_failure_analysis.py::TestFailurePatternDetector::test_analyze_failure_characteristics - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_failure_analysis.py::TestRootCauseAnalyzer::test_analyze_root_causes - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_failure_analysis.py::TestRootCauseAnalyzer::test_prepare_causal_data - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_failure_analysis.py::TestRootCauseAnalyzer::test_extract_causal_features - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_failure_analysis.py::TestFailureAnalysisEngine::test_analyze_failures - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_failure_analysis.py::TestFailureAnalysisEngine::test_calculate_failure_severity - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_failure_analysis.py::TestFailureAnalysisEngine::test_extract_common_triggers - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_failure_analysis.py::TestFailureAnalysisIntegration::test_end_to_end_failure_analysis - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_failure_analysis.py::TestFailureAnalysisIntegration::test_pattern_detection_with_real_clustering - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_failure_analysis.py::TestFailureAnalysisIntegration::test_failure_signature_analysis - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_failure_analysis.py::TestFailureAnalysisIntegration::test_root_cause_analysis_with_real_data - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_model_evaluation.py::TestModelEvaluator::test_evaluate_ensemble_model - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_model_evaluation.py::TestModelEvaluator::test_evaluate_online_model - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_model_evaluation.py::TestModelEvaluationIntegration::test_complete_evaluation_workflow - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_pattern_mining.py::TestPrefixSpanMiner::test_mine_patterns - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_pattern_mining.py::TestPrefixSpanMiner::test_convert_to_item_sequences - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_pattern_mining.py::TestSPADEMiner::test_mine_patterns - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_pattern_mining.py::TestSPADEMiner::test_build_vertical_database - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_pattern_mining.py::TestSPADEMiner::test_find_frequent_1_sequences - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_pattern_mining.py::TestPatternMiningEngine::test_mine_behavioral_patterns - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_pattern_mining.py::TestPatternMiningIntegration::test_end_to_end_pattern_mining - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_pattern_mining.py::TestPatternMiningIntegration::test_pattern_mining_performance - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_prediction_models.py::TestEnsemblePredictor::test_train - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_prediction_models.py::TestEnsemblePredictor::test_prepare_features - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_prediction_models.py::TestEnsemblePredictor::test_extract_sequence_features - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_prediction_models.py::TestEnsemblePredictor::test_extract_static_features - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_prediction_models.py::TestEnsemblePredictor::test_identify_risk_factors - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_prediction_models.py::TestPredictionModelsIntegration::test_ensemble_prediction_workflow - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_prediction_models.py::TestPredictionModelsIntegration::test_online_learning_workflow - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_compare_behavioral_patterns - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_analyze_pattern_significance - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_correlation_analysis - TypeError: BeliefState.__init__() got an unexpected keyword argument 'belief_id'\nERROR tests/unit/test_statistical_analysis.py::TestStatisticalAnalyzer::test_extract_epistemic_features - TypeError: BeliefState.__init__() got an unexpected keyword argument 'belief_id'\nERROR tests/unit/test_statistical_analysis.py::TestStatisticalAnalysisIntegration::test_complete_pattern_comparison_workflow - TypeError: ExecutionStep.__init__() got an unexpected keyword argument 'step_type'\nERROR tests/unit/test_statistical_analysis.py::TestStatisticalAnalysisIntegration::test_correlation_analysis_workflow - TypeError: BeliefState.__init__() got an unexpected keyword argument 'belief_id'\n===== 46 failed, 596 passed, 23 warnings, 39 errors in 107.12s (0:01:47) ======\n",
      "stderr": ""
    },
    "Integration Tests": {
      "success": false,
      "execution_time": 19.512537479400635,
      "return_code": 2,
      "tests_run": 0,
      "tests_passed": 0,
      "tests_failed": 0,
      "tests_skipped": 0,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.11.9, pytest-8.4.1, pluggy-1.5.0 -- C:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\ncachedir: .pytest_cache\nrootdir: D:\\ESCAI\nconfigfile: pyproject.toml\nplugins: anyio-3.7.1, langsmith-0.4.4, asyncio-1.1.0, mock-3.14.1\nasyncio: mode=Mode.AUTO, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 241 items / 1 error\n\n=================================== ERRORS ====================================\n____ ERROR collecting tests/integration/test_error_handling_integration.py ____\nImportError while importing test module 'D:\\ESCAI\\tests\\integration\\test_error_handling_integration.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1204: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1176: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1147: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:690: in _load_unlocked\n    ???\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\ntests\\integration\\test_error_handling_integration.py:31: in <module>\n    from escai_framework.core.pattern_analyzer import PatternAnalyzer\nE   ImportError: cannot import name 'PatternAnalyzer' from 'escai_framework.core.pattern_analyzer' (D:\\ESCAI\\escai_framework\\core\\pattern_analyzer.py)\n=========================== short test summary info ===========================\nERROR tests/integration/test_error_handling_integration.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n============================== 1 error in 15.69s ==============================\n",
      "stderr": ""
    },
    "Performance Tests": {
      "success": false,
      "execution_time": 17.465638160705566,
      "return_code": 1,
      "tests_run": 7,
      "tests_passed": 0,
      "tests_failed": 7,
      "tests_skipped": 0,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.11.9, pytest-8.4.1, pluggy-1.5.0 -- C:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\ncachedir: .pytest_cache\nrootdir: D:\\ESCAI\nconfigfile: pyproject.toml\nplugins: anyio-3.7.1, langsmith-0.4.4, asyncio-1.1.0, mock-3.14.1\nasyncio: mode=Mode.AUTO, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 7 items\n\ntests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_langchain_instrumentor_overhead FAILED\ntests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_epistemic_extractor_performance FAILED\ntests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_pattern_analyzer_performance FAILED\ntests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_concurrent_monitoring_performance FAILED\ntests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_memory_usage_monitoring FAILED\ntests/performance/test_monitoring_overhead.py::TestScalabilityPerformance::test_agent_scaling FAILED\ntests/performance/test_monitoring_overhead.py::TestScalabilityPerformance::test_event_throughput_scaling FAILED\n\n================================== FAILURES ===================================\n_________ TestMonitoringOverhead.test_langchain_instrumentor_overhead _________\ntests\\performance\\test_monitoring_overhead.py:136: in test_langchain_instrumentor_overhead\n    baseline_times = await suite.measure_baseline_performance(agent, iterations=50)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests\\performance\\test_monitoring_overhead.py:56: in measure_baseline_performance\n    await agent.execute_task(complexity=np.random.randint(1, 5))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: MockAgent.execute_task() got an unexpected keyword argument 'complexity'\n_________ TestMonitoringOverhead.test_epistemic_extractor_performance _________\ntests\\performance\\test_monitoring_overhead.py:166: in test_epistemic_extractor_performance\n    epistemic_state = await extractor.extract_beliefs(logs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nescai_framework\\core\\epistemic_extractor.py:164: in extract_beliefs\n    if event.event_type in [\n       ^^^^^^^^^^^^^^^^\nE   AttributeError: 'dict' object has no attribute 'event_type'\n__________ TestMonitoringOverhead.test_pattern_analyzer_performance ___________\ntests\\performance\\test_monitoring_overhead.py:191: in test_pattern_analyzer_performance\n    sequences = test_data_generator.generate_behavioral_sequences(100)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests\\conftest.py:334: in generate_behavioral_sequences\n    sequences.append(ExecutionSequence(\nE   TypeError: ExecutionSequence.__init__() got an unexpected keyword argument 'success'\n________ TestMonitoringOverhead.test_concurrent_monitoring_performance ________\nescai_framework\\instrumentation\\langchain_instrumentor.py:682: in capture_event\n    raise EventProcessingError(f\"Invalid event: {event.event_id}\")\nE   escai_framework.instrumentation.base_instrumentor.EventProcessingError: Invalid event: agent_0_event_0\n\nDuring handling of the above exception, another exception occurred:\ntests\\performance\\test_monitoring_overhead.py:250: in test_concurrent_monitoring_performance\n    await asyncio.gather(*tasks)\ntests\\performance\\test_monitoring_overhead.py:233: in monitor_agent\n    await instrumentor.capture_event(AgentEvent(\nescai_framework\\instrumentation\\langchain_instrumentor.py:696: in capture_event\n    raise EventProcessingError(f\"Failed to capture event: {str(e)}\")\nE   escai_framework.instrumentation.base_instrumentor.EventProcessingError: Failed to capture event: Invalid event: agent_0_event_0\n_____________ TestMonitoringOverhead.test_memory_usage_monitoring _____________\ntests\\performance\\test_monitoring_overhead.py:285: in test_memory_usage_monitoring\n    event_type=EventType.DECISION_MADE,\n               ^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\enum.py:786: in __getattr__\n    raise AttributeError(name) from None\nE   AttributeError: DECISION_MADE\n________________ TestScalabilityPerformance.test_agent_scaling ________________\nescai_framework\\instrumentation\\langchain_instrumentor.py:682: in capture_event\n    raise EventProcessingError(f\"Invalid event: {event.event_id}\")\nE   escai_framework.instrumentation.base_instrumentor.EventProcessingError: Invalid event: scale_agent_0_task_0\n\nDuring handling of the above exception, another exception occurred:\ntests\\performance\\test_monitoring_overhead.py:345: in test_agent_scaling\n    await asyncio.gather(*tasks)\ntests\\performance\\test_monitoring_overhead.py:334: in agent_task\n    await i.capture_event(AgentEvent(\nescai_framework\\instrumentation\\langchain_instrumentor.py:696: in capture_event\n    raise EventProcessingError(f\"Failed to capture event: {str(e)}\")\nE   escai_framework.instrumentation.base_instrumentor.EventProcessingError: Failed to capture event: Invalid event: scale_agent_0_task_0\n__________ TestScalabilityPerformance.test_event_throughput_scaling ___________\ntests\\performance\\test_monitoring_overhead.py:381: in test_event_throughput_scaling\n    events = [\ntests\\performance\\test_monitoring_overhead.py:385: in <listcomp>\n    event_type=EventType.DECISION_MADE,\n               ^^^^^^^^^^^^^^^^^^^^^^^\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\enum.py:786: in __getattr__\n    raise AttributeError(name) from None\nE   AttributeError: DECISION_MADE\n============================== warnings summary ===============================\ntests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_epistemic_extractor_performance\n  C:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============================ slowest 10 durations =============================\n6.07s call     tests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_epistemic_extractor_performance\n0.01s setup    tests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_memory_usage_monitoring\n0.00s setup    tests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_langchain_instrumentor_overhead\n0.00s setup    tests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_epistemic_extractor_performance\n0.00s call     tests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_concurrent_monitoring_performance\n0.00s setup    tests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_pattern_analyzer_performance\n0.00s setup    tests/performance/test_monitoring_overhead.py::TestScalabilityPerformance::test_event_throughput_scaling\n0.00s teardown tests/performance/test_monitoring_overhead.py::TestScalabilityPerformance::test_event_throughput_scaling\n0.00s setup    tests/performance/test_monitoring_overhead.py::TestScalabilityPerformance::test_agent_scaling\n0.00s setup    tests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_concurrent_monitoring_performance\n=========================== short test summary info ===========================\nFAILED tests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_langchain_instrumentor_overhead - TypeError: MockAgent.execute_task() got an unexpected keyword argument 'complexity'\nFAILED tests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_epistemic_extractor_performance - AttributeError: 'dict' object has no attribute 'event_type'\nFAILED tests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_pattern_analyzer_performance - TypeError: ExecutionSequence.__init__() got an unexpected keyword argument 'success'\nFAILED tests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_concurrent_monitoring_performance - escai_framework.instrumentation.base_instrumentor.EventProcessingError: Failed to capture event: Invalid event: agent_0_event_0\nFAILED tests/performance/test_monitoring_overhead.py::TestMonitoringOverhead::test_memory_usage_monitoring - AttributeError: DECISION_MADE\nFAILED tests/performance/test_monitoring_overhead.py::TestScalabilityPerformance::test_agent_scaling - escai_framework.instrumentation.base_instrumentor.EventProcessingError: Failed to capture event: Invalid event: scale_agent_0_task_0\nFAILED tests/performance/test_monitoring_overhead.py::TestScalabilityPerformance::test_event_throughput_scaling - AttributeError: DECISION_MADE\n======================== 7 failed, 1 warning in 13.77s ========================\n",
      "stderr": "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nDevice set to use cpu\n"
    },
    "Load Tests": {
      "success": false,
      "execution_time": 1.7533860206604004,
      "return_code": 4,
      "tests_run": 0,
      "tests_passed": 0,
      "tests_failed": 0,
      "tests_skipped": 0,
      "stdout": "",
      "stderr": "ERROR: usage: __main__.py [options] [file_or_dir] [file_or_dir] [...]\n__main__.py: error: unrecognized arguments: --timeout=300\n  inifile: D:\\ESCAI\\pyproject.toml\n  rootdir: D:\\ESCAI\n\n"
    },
    "Accuracy Tests": {
      "success": false,
      "execution_time": 11.719813585281372,
      "return_code": 2,
      "tests_run": 0,
      "tests_passed": 0,
      "tests_failed": 0,
      "tests_skipped": 0,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.11.9, pytest-8.4.1, pluggy-1.5.0 -- C:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\ncachedir: .pytest_cache\nrootdir: D:\\ESCAI\nconfigfile: pyproject.toml\nplugins: anyio-3.7.1, langsmith-0.4.4, asyncio-1.1.0, mock-3.14.1\nasyncio: mode=Mode.AUTO, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 0 items / 1 error\n\n=================================== ERRORS ====================================\n__________ ERROR collecting tests/accuracy/test_ml_model_accuracy.py __________\nImportError while importing test module 'D:\\ESCAI\\tests\\accuracy\\test_ml_model_accuracy.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1204: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1176: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1147: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:690: in _load_unlocked\n    ???\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\ntests\\accuracy\\test_ml_model_accuracy.py:19: in <module>\n    from escai_framework.analytics.prediction_models import PredictionModelManager\nE   ImportError: cannot import name 'PredictionModelManager' from 'escai_framework.analytics.prediction_models' (D:\\ESCAI\\escai_framework\\analytics\\prediction_models.py)\n=========================== short test summary info ===========================\nERROR tests/accuracy/test_ml_model_accuracy.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n============================== 1 error in 8.14s ===============================\n",
      "stderr": ""
    },
    "End-to-End Tests": {
      "success": false,
      "execution_time": 18.2085382938385,
      "return_code": 2,
      "tests_run": 0,
      "tests_passed": 0,
      "tests_failed": 0,
      "tests_skipped": 0,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.11.9, pytest-8.4.1, pluggy-1.5.0 -- C:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\ncachedir: .pytest_cache\nrootdir: D:\\ESCAI\nconfigfile: pyproject.toml\nplugins: anyio-3.7.1, langsmith-0.4.4, asyncio-1.1.0, mock-3.14.1\nasyncio: mode=Mode.AUTO, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 0 items / 1 error\n\n=================================== ERRORS ====================================\n____________ ERROR collecting tests/e2e/test_complete_workflows.py ____________\nImportError while importing test module 'D:\\ESCAI\\tests\\e2e\\test_complete_workflows.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1204: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1176: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1147: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:690: in _load_unlocked\n    ???\nC:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\ntests\\e2e\\test_complete_workflows.py:22: in <module>\n    from escai_framework.api.main import create_app\nE   ImportError: cannot import name 'create_app' from 'escai_framework.api.main' (D:\\ESCAI\\escai_framework\\api\\main.py)\n=========================== short test summary info ===========================\nERROR tests/e2e/test_complete_workflows.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n============================== 1 error in 14.55s ==============================\n",
      "stderr": "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nDevice set to use cpu\n"
    },
    "Coverage Analysis": {
      "success": false,
      "error": "No coverage data generated",
      "coverage_percentage": 0
    }
  },
  "requirements_validation": {
    "unit_tests_pass": false,
    "integration_tests_pass": false,
    "performance_requirements_met": false,
    "load_requirements_met": false,
    "accuracy_requirements_met": false,
    "e2e_tests_pass": false,
    "coverage_above_95_percent": false
  }
}